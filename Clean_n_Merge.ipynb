{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the scrape artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl = pd.read_csv('../part-01/fpl_raw_scrape.csv')\n",
    "shaw = pd.read_csv('../part-01/shaw.csv')\n",
    "git = pd.read_csv('../part-01/fpl_18_19.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scrape coudn't pick up shaw due to timeout, so seperatly scraped and will be concatenated during cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "shaw.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpl['player'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think 35 from shaw and another from an empty player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl.dropna(inplace=True, subset=['player'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18603, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 29)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shaw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl=pd.concat([fpl,shaw], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 Danny Wards in the PL!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 11.0,\n",
       " 12.0,\n",
       " 13.0,\n",
       " 14.0,\n",
       " 15.0,\n",
       " 16.0,\n",
       " 17.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 20.0,\n",
       " 21.0,\n",
       " 22.0,\n",
       " 23.0,\n",
       " 24.0,\n",
       " 25.0,\n",
       " 26.0,\n",
       " 27.0,\n",
       " 28.0,\n",
       " 29.0,\n",
       " 30.0,\n",
       " 32.0,\n",
       " 32.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 35.0,\n",
       " 36.0,\n",
       " 37.0,\n",
       " 38.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 11.0,\n",
       " 12.0,\n",
       " 13.0,\n",
       " 14.0,\n",
       " 15.0,\n",
       " 16.0,\n",
       " 17.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 20.0,\n",
       " 21.0,\n",
       " 22.0,\n",
       " 23.0,\n",
       " 24.0,\n",
       " 25.0,\n",
       " 26.0,\n",
       " 27.0,\n",
       " 28.0,\n",
       " 29.0,\n",
       " 30.0,\n",
       " 31.0,\n",
       " 32.0,\n",
       " 33.0,\n",
       " 34.0,\n",
       " 35.0,\n",
       " 36.0,\n",
       " 37.0,\n",
       " 38.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fpl[fpl['player']=='Danny Ward']['gw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When importing git the danny ward that got 19 points was danny ward 1, danny ward 2 got 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git[git['player']=='danny ward 1']['total_points'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git[git['player']=='danny ward 2']['total_points'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cardiff', 'Leicester'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpl[fpl['player']=='Danny Ward']['team'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.0\n"
     ]
    }
   ],
   "source": [
    "print(fpl[(fpl['player']=='Danny Ward')&\n",
    "    (fpl['team']=='Cardiff')]['pts'].sum())\n",
    "danny_1 = fpl[(fpl['player']=='Danny Ward')&\n",
    "    (fpl['team']=='Cardiff')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(fpl[(fpl['player']=='Danny Ward')&\n",
    "    (fpl['team']=='Leicester')]['pts'].sum())\n",
    "danny_2 = fpl[(fpl['player']=='Danny Ward')&\n",
    "    (fpl['team']=='Leicester')].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dannies are now renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl.loc[danny_1,'player']='Danny Ward 1'\n",
    "fpl.loc[danny_2,'player']='Danny Ward 2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to clean up some of the columns. Value, has a currency sign while selected, transfers have commas and the opposition values have lots of white space and escape keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_fix(value):\n",
    "    if type(value) == float:\n",
    "        return value\n",
    "    else:\n",
    "        return float(value[1:])\n",
    "\n",
    "def selected_by_fix(selected_by):\n",
    "    if type(selected_by) == float:\n",
    "        return selected_by\n",
    "    else:\n",
    "        return float(selected_by.replace(',',''))\n",
    "\n",
    "def net_transfers_fix(net_transfers):\n",
    "    if type(net_transfers) == float:\n",
    "        return net_transfers\n",
    "    else:\n",
    "        return float(net_transfers.replace(',',''))\n",
    "    \n",
    "def opp_split(opp):\n",
    "    '''\n",
    "    lists and removes escape keys\n",
    "    in opp string. Used in extracting\n",
    "    data from the opp feature. Which can \n",
    "    contain opponent, home\\away and score.\n",
    "    '''\n",
    "    if '\\n' in opp:\n",
    "        wordlist = [word.replace('\\n','') for word in opp.split(' ') if (word != '') and (word != '\\n')]\n",
    "        if len(wordlist) == 3:\n",
    "            wordlist = [wordlist[0]+wordlist[1], wordlist[2]]\n",
    "        return wordlist\n",
    "    else:\n",
    "        other = opp[:7]\n",
    "        score = opp[8:]\n",
    "        wordlist = [word for word in other.split(' ')] + [score]\n",
    "        return wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl['value'] = fpl['value'].apply(value_fix)\n",
    "fpl['selected_by'] = fpl['selected_by'].apply(selected_by_fix)\n",
    "fpl['net_transfers'] = fpl['net_transfers'].apply(net_transfers_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opposition still has lots of information that should be seperated out into different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opp_extract_opposition(opp):\n",
    "    '''\n",
    "    if opp is not np.nan(float) then \n",
    "    take then take first element from \n",
    "    listed value.\n",
    "    '''\n",
    "    if type(opp) != float:\n",
    "        opposition = opp_split(opp)[0]\n",
    "        return opposition\n",
    "    else:\n",
    "        return opp\n",
    "\n",
    "def opp_extract_is_home(opp):\n",
    "    '''\n",
    "    if opp is not np.nan(float) then \n",
    "    take then take second element. If\n",
    "    second == H, return 1 else 0.\n",
    "    '''\n",
    "    if type(opp) != float:\n",
    "        is_home = opp_split(opp)[1]\n",
    "        if is_home == '(H)':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return opp\n",
    "\n",
    "def opp_extract_score(opp):\n",
    "    '''\n",
    "    if opp is not np.nan(float) then \n",
    "    take then take last element, if\n",
    "    it exists else return np.nan (game\n",
    "    hasnt happened as off data scrape).\n",
    "    return last element.\n",
    "    '''\n",
    "    if type(opp) != float:\n",
    "        infolist = opp_split(opp)\n",
    "        if len(infolist) == 2:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return infolist[-1]\n",
    "    else:\n",
    "        return opp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl['opposition'] = fpl['opp'].apply(opp_extract_opposition)\n",
    "fpl['is_home'] = fpl['opp'].apply(opp_extract_is_home)\n",
    "fpl['score'] = fpl['opp'].apply(opp_extract_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixtures and game history are in the same column and use different names for teams. SOU becomes Southampton in fixtures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    'Southampton':'SOU',\n",
    "    'Bournemouth':'BOU',\n",
    "    'WestHam':'WHU',\n",
    "    'Cardiff':'CAR',\n",
    "    'Everton':'EVE',\n",
    "    'ManUtd':'MUN',\n",
    "    'Chelsea':'CHE',\n",
    "    'Brighton':'BHA',\n",
    "    'Spurs':'TOT',\n",
    "    'Huddersfield':'HUD',\n",
    "    'Newcastle':'NEW',\n",
    "    'Wolves':'WOL',\n",
    "    'Arsenal':'ARS',\n",
    "    'ManCity':'MCI',\n",
    "    'Liverpool':'LIV',\n",
    "    'CrystalPalace':'CRY',\n",
    "    'Fulham':'FUL',\n",
    "    'Leicester':'LEI',\n",
    "    'Burnley':'BUR',\n",
    "    'Watford':'WAT'\n",
    "}\n",
    "def map_names(oppo):\n",
    "    if oppo in names.keys():\n",
    "        oppo = names[oppo]\n",
    "    return oppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl['opposition'] = fpl['opposition'].apply(map_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the score diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_diff(score):\n",
    "    if type(score) == float:\n",
    "        return score\n",
    "    else:\n",
    "        return int(score[0]) - int(score[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl['score_diff'] = fpl['score'].apply(score_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all information is properly stored there is no need for the original opp column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl.drop('opp', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18641 entries, 0 to 37\n",
      "Data columns (total 32 columns):\n",
      "gw                    18641 non-null float64\n",
      "player                18641 non-null object\n",
      "team                  18641 non-null object\n",
      "position              18641 non-null object\n",
      "form                  18641 non-null float64\n",
      "report                3368 non-null object\n",
      "pts                   17057 non-null float64\n",
      "mins                  17057 non-null float64\n",
      "goals                 17057 non-null float64\n",
      "assists               17057 non-null float64\n",
      "clean                 17057 non-null float64\n",
      "conceded              17057 non-null float64\n",
      "own_goals             17057 non-null float64\n",
      "pen_saved             17057 non-null float64\n",
      "pen_missed            17057 non-null float64\n",
      "yellows               17057 non-null float64\n",
      "red                   17057 non-null float64\n",
      "saves                 17057 non-null float64\n",
      "bonus                 17057 non-null float64\n",
      "bonus_sys             17057 non-null float64\n",
      "influence             17057 non-null float64\n",
      "creativity            17057 non-null float64\n",
      "threat                17057 non-null float64\n",
      "ict_index             17057 non-null float64\n",
      "net_transfers         17057 non-null float64\n",
      "selected_by           17057 non-null float64\n",
      "value                 17057 non-null float64\n",
      "fixture_difficulty    1584 non-null float64\n",
      "opposition            18641 non-null object\n",
      "is_home               18641 non-null int64\n",
      "score                 17057 non-null object\n",
      "score_diff            17057 non-null float64\n",
      "dtypes: float64(25), int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "fpl.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no missing in gw, player, team, position, form, opposition and is_home. However, form is repeated over every player rather than the recorded changes in form it is just the last recorded form. Report is the injury status of players when they were scrapped, if players were not injured when scraped then report is missing. Report is also constant over the players rows rather than changing. Missing values in fixture_difficulty are for rows were the game hasnt occured yet as of the scrape, taken in week 34.\n",
    "\n",
    "All other columns have missing values were games havnt orrcured yet, i.e. after week 34."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can now merge the FPL data with the GIT data from the same season. Before that though the rows need to grouped by rounds, becuase of double game weeks some times players get two rows where they should only get one, both rows describing different games in the double game week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gw, player, team, position, net_transfers and value should all remain constand when combining games in the same gameweek. opp should be dummified before the games are combined, then the row will have two 1s rather than one 1 for that gameweek. bonus_sys is between -100, 100 (assumed) and so should remain a negative/positive %. A new two week dummy should be created 1 indicating that the player has a double game week. All other columns can be summed. \n",
    "\n",
    "It could be argued that mins and saves should not be summed but a mean taken, or seperated into two columns for first and second game. This is because they are not strictly linearly related as they have thresholds. A gk with 2 saves in one game and 1 in another will get 0 points for both games, while a gk with 3 in one game and 0 in the next will get a point for saves. However, i dont believe adding columns will help the model. For thouroughness I create a column of meaned mins and saves, and anther for summed, and will test models to see which is better, i dont expect to see any meaningfull difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#easy to sum along columns when grouping\n",
    "fpl = pd.get_dummies(fpl, columns = ['opposition'])\n",
    "git = pd.get_dummies(git, columns = ['opponent_team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to later create a dummy if row is double game week\n",
    "git['is_double'] = 0\n",
    "fpl['is_double'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_double(alist):\n",
    "    '''\n",
    "    if a group is made then this returns 1\n",
    "    '''\n",
    "    the_list = [e for e in alist]\n",
    "    if len(the_list) > 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def concater(alist):\n",
    "    '''\n",
    "    joins to strings when grouping them\n",
    "    '''\n",
    "    return ' & '.join([str(e) for e in alist])\n",
    "\n",
    "def constantinople(alist):\n",
    "    '''\n",
    "    takes the first value (used for constants over weeks like value or position)\n",
    "    '''\n",
    "    return [e for e in alist][0]\n",
    "\n",
    "def home_away(alist):\n",
    "    '''\n",
    "    returns a list of is_home values if \n",
    "    double week. This can later be delt with\n",
    "    consistently over all seasons\n",
    "    '''\n",
    "    the_value = [e for e in alist]\n",
    "    if len(the_value) == 1:\n",
    "        return the_value[0]\n",
    "    else:\n",
    "        return the_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agg_git(df, mean_alt):\n",
    "    '''\n",
    "    creates the agg dict for the git groupby\n",
    "    '''\n",
    "    sum_me = ['assists', 'attempted_passes', 'big_chances_created',\n",
    "       'big_chances_missed', 'bonus','clean_sheets',\n",
    "       'clearances_blocks_interceptions', 'completed_passes', 'creativity',\n",
    "       'dribbles', 'errors_leading_to_goal',\n",
    "       'errors_leading_to_goal_attempt','fouls', 'goals_conceded', 'offside', 'open_play_crosses',\n",
    "       'goals_scored','influence', 'key_passes','own_goals',\n",
    "       'penalties_conceded', 'penalties_missed', 'penalties_saved',\n",
    "       'recoveries', 'red_cards','tackled',\n",
    "       'tackles', 'target_missed','threat',\n",
    "       'total_points','winning_goals', 'yellow_cards',\n",
    "        'opponent_team_1', 'opponent_team_2', 'opponent_team_3',\n",
    "       'opponent_team_4', 'opponent_team_5', 'opponent_team_6',\n",
    "       'opponent_team_7', 'opponent_team_8', 'opponent_team_9',\n",
    "       'opponent_team_10', 'opponent_team_11', 'opponent_team_12',\n",
    "       'opponent_team_13', 'opponent_team_14', 'opponent_team_15',\n",
    "       'opponent_team_16', 'opponent_team_17', 'opponent_team_18',\n",
    "       'opponent_team_19', 'opponent_team_20']\n",
    "    \n",
    "    mean_me_alt = ['minutes', 'saves']\n",
    "    sum_me_alt = ['minutes', 'saves']\n",
    "\n",
    "    mean_me = ['bps', 'ea_index', 'ict_index'] #idk what eaindex is\n",
    "\n",
    "    constant = ['id', 'player', 'transfers_balance', 'transfers_in', 'transfers_out','value', 'element', 'selected', 'loaned_in', 'loaned_out', 'round']\n",
    "\n",
    "    concat = ['fixture','kickoff_time', 'kickoff_time_formatted']\n",
    "\n",
    "    other = ['team_a_score', 'team_h_score','was_home'] \n",
    "    agg = {}\n",
    "    if mean_alt == False:\n",
    "        sum_me += sum_me_alt\n",
    "    else:\n",
    "        mean_me += mean_me_alt\n",
    "        \n",
    "    for col in df.columns:\n",
    "        if col in sum_me:\n",
    "            agg[col] = 'sum'\n",
    "        elif col in mean_me:\n",
    "            agg[col] = 'mean'\n",
    "        elif col in constant:\n",
    "            agg[col] = constantinople\n",
    "        elif col in concat:\n",
    "            agg[col] = concater\n",
    "        elif col == 'is_double':\n",
    "            agg[col] = is_double\n",
    "        else:\n",
    "            agg[col] = home_away\n",
    "    \n",
    "    return agg\n",
    "\n",
    "def create_agg_fpl(df, mean_alt):\n",
    "    '''\n",
    "    creates the agg dict for the fpl groupby\n",
    "    '''\n",
    "    sum_me = ['pts', 'goals', 'assists', 'clean', 'conceded', 'own_goals', 'pen_saved',\n",
    "        'pen_missed', 'yellows', 'red', 'bonus','influence', 'creativity', 'threat', \n",
    "        'net_transfers', 'opposition_ARS', 'opposition_BHA',\n",
    "        'opposition_BOU', 'opposition_BUR', 'opposition_CAR', 'opposition_CHE','opposition_CRY', \n",
    "        'opposition_EVE', 'opposition_FUL', 'opposition_HUD', 'opposition_LEI', 'opposition_LIV', \n",
    "        'opposition_MCI', 'opposition_MUN','opposition_NEW', 'opposition_SOU', 'opposition_TOT', \n",
    "        'opposition_WAT', 'opposition_WHU', 'opposition_WOL']\n",
    "    mean_me_alt = ['mins', 'saves', 'score_diff']\n",
    "    sum_me_alt = ['mins', 'saves', 'score_diff']\n",
    "    \n",
    "    mean_me = ['fixture_difficulty', 'bonus_sys', 'ict_index']\n",
    "    \n",
    "    constant = ['player', 'team', 'position', 'form', 'report', 'gw', 'selected_by', 'value']\n",
    "    \n",
    "    concat = ['score']\n",
    "    other = ['is_home']#for clarity rather than function\n",
    "    \n",
    "    agg = {}\n",
    "    if mean_alt == False:\n",
    "        sum_me += sum_me_alt\n",
    "    else:\n",
    "        mean_me += mean_me_alt\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col in sum_me:\n",
    "            agg[col] = 'sum'\n",
    "        elif col in mean_me:\n",
    "            agg[col] = 'mean'\n",
    "        elif col in constant:\n",
    "            agg[col] = constantinople\n",
    "        elif col in concat:\n",
    "            agg[col] = concater\n",
    "        elif col in other:\n",
    "            agg[col] = home_away\n",
    "        elif col == 'is_double':\n",
    "            agg[col] = is_double\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_fpl_mean = create_agg_fpl(fpl, mean_alt = True)\n",
    "agg_fpl_sum = create_agg_fpl(fpl, mean_alt = False)\n",
    "agg_git_mean = create_agg_git(git, mean_alt = True)\n",
    "agg_git_sum = create_agg_git(git, mean_alt = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl_m = fpl.groupby(['player', 'gw']).agg(agg_fpl_mean)\n",
    "fpl_s = fpl.groupby(['player', 'gw']).agg(agg_fpl_sum)\n",
    "git_m = git.groupby(['player', 'round']).agg(agg_git_mean)\n",
    "git_s = git.groupby(['player', 'round']).agg(agg_git_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now need to match the indexes of the two dataframes, and lowercase the player names in the FPL dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpl_m['player'] = fpl_m['player'].apply(lambda x: x.lower())\n",
    "\n",
    "fpl_m.index = [fpl_m['player'], fpl_m['gw']]\n",
    "git_m.index = [git_m['player'], git_m['round']]\n",
    "\n",
    "fpl_m = fpl_m[fpl_m['gw']<35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets are now ready to be merged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = git_m.merge(fpl_m, how='outer', left_on=git_m.index, right_on=fpl_m.index)\n",
    "df3.columns = [col.replace('_x', '') for col in df3.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is now ready to be merged with the other seasons datasets from git, once \n",
    "they too are cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../part-01/fpl_16_17.csv')\n",
    "df2 = pd.read_csv('../part-01/fpl_17_18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop('fixture', axis=1, inplace=True)\n",
    "df2.drop('fixture', axis=1, inplace=True)\n",
    "df3.drop('fixture', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_2016 = ['ARS', 'BOU', 'BUR', 'CHE', 'CRY', 'EVE', 'HUL', 'LEI',\n",
    "             'LIV', 'MCI', 'MUN', 'MID', 'SOU', 'STO', 'SUN', 'SWA',\n",
    "             'TOT', 'WAT', 'WBA', 'WHU']\n",
    "\n",
    "teams_2017 = ['ARS', 'BOU', 'BHA', 'BUR', 'CHE', 'CRY', 'EVE', 'HUD',\n",
    "             'LEI', 'LIV', 'MCI', 'MUN', 'NEW', 'SOU', 'STO', 'SWA',\n",
    "             'TOT', 'WAT', 'WBA', 'WHU']\n",
    "\n",
    "teams_2018 = ['ARS', 'BOU', 'BHA', 'BUR', 'CAR', 'CHE', 'CRY', 'EVE',\n",
    "             'FUL', 'HUD', 'LEI', 'LIV', 'MCI', 'MUN', 'NEW', 'SOU',\n",
    "             'TOT', 'WAT', 'WHU', 'WOL']\n",
    "\n",
    "team_key_2016 = {'laurent koscielny':'ARS',\n",
    "                'simon francis':'BOU',\n",
    "                'tom heaton':'BUR',\n",
    "                'john terry':'CHE',\n",
    "                'scott dann':'CRY',\n",
    "                'phil jagielka':'EVE',\n",
    "                'michael dawson':'HUL',\n",
    "                'wes morgan':'LEI',\n",
    "                'jordan henderson':'LIV',\n",
    "                'vincent kompany':'MCI',\n",
    "                'wayne rooney':'MUN',\n",
    "                'grant leadbitter':'MID',\n",
    "                'steven davis':'SOU',\n",
    "                'ryan shawcross':'STO',\n",
    "                \"john o'shea\":'SUN',\n",
    "                'leon britton':'SWA',\n",
    "                'hugo lloris':'TOT',\n",
    "                'troy deeney':'WAT',\n",
    "                'darren fletcher':'WBA',\n",
    "                'mark noble':'WHU'}\n",
    "\n",
    "team_key_2017 = {'per mertesacker':'ARS',\n",
    "                'simon francis':'BOU',\n",
    "                'bruno saltor grau':'BHA',\n",
    "                'tom heaton':'BUR',\n",
    "                'gary cahill':'CHE',\n",
    "                'jason puncheon':'CRY',\n",
    "                'phil jagielka':'EVE',\n",
    "                'tommy smith':'HUD',\n",
    "                'wes morgan':'LEI',\n",
    "                'jordan henderson':'LIV',\n",
    "                'vincent kompany':'MCI',\n",
    "                'michael carrick':'MUN',\n",
    "                'jamaal lascelles':'NEW',\n",
    "                'steven davis':'SOU',\n",
    "                'ryan shawcross':'STO',\n",
    "                'angel rangel':'SWA',\n",
    "                'hugo lloris':'TOT',\n",
    "                'troy deeney':'WAT',\n",
    "                'jonny evans':'WBA',\n",
    "                'mark noble':'WHU'}\n",
    "\n",
    "team_key_2018 = {\n",
    "                'laurent koscielny':'ARS',\n",
    "                'simon francis':'BOU',\n",
    "                'bruno saltor grau':'BHA',\n",
    "                'tom heaton':'BUR',\n",
    "                'sean morrison':'CAR',\n",
    "                'gary cahill':'CHE',\n",
    "                'luka milivojevic':'CRY',\n",
    "                'phil jagielka':'EVE',\n",
    "                'tom cairney':'FUL',\n",
    "                'tommy smith':'HUD',\n",
    "                'wes morgan':'LEI',\n",
    "                'jordan henderson':'LIV',\n",
    "                'vincent kompany':'MCI',\n",
    "                'antonio valencia':'MUN',\n",
    "                'jamaal lascelles':'NEW',\n",
    "                'pierre-emile højbjerg':'SOU',\n",
    "                'hugo lloris':'TOT',\n",
    "                'troy deeney':'WAT',\n",
    "                'mark noble':'WHU',\n",
    "                'conor coady':'WOL'\n",
    "}\n",
    "\n",
    "num_team_2016 = {\n",
    "    1:'ARS',\n",
    "    2:'BOU',\n",
    "    3:'BUR',\n",
    "    4:'CHE',\n",
    "    5:'CRY',\n",
    "    6:'EVE',\n",
    "    7:'HUL',\n",
    "    8:'LEI',\n",
    "    9:'LIV',\n",
    "    10:'MCI',\n",
    "    11:'MUN',\n",
    "    12:'MID',\n",
    "    13:'SOU',\n",
    "    14:'STO',\n",
    "    15:'SUN',\n",
    "    16:'SWA',\n",
    "    17:'TOT',\n",
    "    18:'WAT',\n",
    "    19:'WBA',\n",
    "    20:'WHU'\n",
    "}\n",
    "\n",
    "num_team_2017 = {\n",
    "    1:'ARS',\n",
    "    2:'BOU',\n",
    "    3:'BHA',\n",
    "    4:'BUR',\n",
    "    5:'CHE',\n",
    "    6:'CRY',\n",
    "    7:'EVE',\n",
    "    8:'HUD',\n",
    "    9:'LEI',\n",
    "    10:'LIV',\n",
    "    11:'MCI',\n",
    "    12:'MUN',\n",
    "    13:'NEW',\n",
    "    14:'SOU',\n",
    "    15:'STO',\n",
    "    16:'SWA',\n",
    "    17:'TOT',\n",
    "    18:'WAT',\n",
    "    19:'WBA',\n",
    "    20:'WHU' \n",
    "}\n",
    "\n",
    "num_team_2018 = {\n",
    "    1:'ARS',\n",
    "    2:'BOU',\n",
    "    3:'BHA',\n",
    "    4:'BUR',\n",
    "    5:'CAR',\n",
    "    6:'CHE',\n",
    "    7:'CRY',\n",
    "    8:'EVE',\n",
    "    9:'FUL',\n",
    "    10:'HUD',\n",
    "    11:'LEI',\n",
    "    12:'LIV',\n",
    "    13:'MCI',\n",
    "    14:'MUN',\n",
    "    15:'NEW',\n",
    "    16:'SOU',\n",
    "    17:'TOT',\n",
    "    18:'WAT',\n",
    "    19:'WHU',\n",
    "    20:'WOL'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to identify the double game weeks in the git datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r_c_2016 = {}\n",
    "for player in df1['player'].unique():\n",
    "    player_round_counts = df1[(df1['player']==player)]['round'].value_counts()\n",
    "    p_r_c_2016[player] = player_round_counts\n",
    "\n",
    "p_r_c_2017 = {}\n",
    "for player in df2['player'].unique():\n",
    "    player_round_counts = df2[(df2['player']==player)]['round'].value_counts()\n",
    "    p_r_c_2017[player] = player_round_counts\n",
    "    \n",
    "def is_double(row, prc):\n",
    "    player_rounds = prc[row['player']]\n",
    "    if player_rounds[row['round']]!=1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def is_second_make(row, df):\n",
    "    '''\n",
    "    if row has a value count != 1\n",
    "    and prev_gw==curr_gw, then this\n",
    "    row is the second game in a double \n",
    "    game week.\n",
    "    '''\n",
    "    i = row.name\n",
    "    is_double = row['is_double']\n",
    "    gw = row['round']\n",
    "    player = row['player']\n",
    "    if is_double==1:\n",
    "        prev_dub = df.loc[i-1,'is_double']\n",
    "        prev_gw = df.loc[i-1, 'round']\n",
    "        prev_player = df.loc[i-1, 'player']\n",
    "        if (prev_dub==1) and (prev_gw==gw) and (prev_player==player):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['is_double']=df1.apply(is_double, prc=p_r_c_2016, axis=1)\n",
    "df2['is_double']=df2.apply(is_double, prc=p_r_c_2017, axis=1)\n",
    "\n",
    "df1['is_second']=df1.apply(is_second_make, df=df1, axis = 1)\n",
    "df2['is_second']=df2.apply(is_second_make, df=df2, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Players move between teams during transfers. This creates problems in both types of dataset. In the fpl-git 2018/19 dataset we observe teams but not the change as players from the fpl official site do not record past teams only current teams.\n",
    "\n",
    "In the git 2017/18 and 2016/17 datasets we do not observe teams so need some way of identifying both the team and the team movements of players.\n",
    "\n",
    "During each season a team has an official captain that will have remained with the team for at least that entire season. I find each captains fixtures and compare players to this. If they play the same team as a captain then they are in the same team as the captain. This is not robust to double weeks. For the 2016/17 and 2017/18 seasons this doesnt matter as rows are not yet collapsed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_fixtures(df, team_key):\n",
    "    '''\n",
    "    get the features of the captain\n",
    "    for each team, thereby getting\n",
    "    the complete features of each team.\n",
    "    This can later be used to identify the\n",
    "    team of players.\n",
    "    '''\n",
    "    cap_opponents = {}\n",
    "    for cap in team_key.keys():\n",
    "        is_second=False\n",
    "        opps=[]\n",
    "        for gw in df[df['player']==cap]['round'].values:\n",
    "            count = np.count_nonzero(df[df['player']==cap]['round'].values==gw)\n",
    "            if count != 1:\n",
    "                is_double=True\n",
    "            else:\n",
    "                is_double=False\n",
    "            if is_double==False:\n",
    "                opp = df[(df['player']==cap)&(df['round']==gw)]['opponent_team'].values[0]\n",
    "            elif (is_double==True)&(is_second==True):\n",
    "                opp = df[(df['player']==cap)&(df['round']==gw)]['opponent_team'].values[1]\n",
    "                is_second=False\n",
    "            elif (is_double==True)&(is_second==False):\n",
    "                opp = df[(df['player']==cap)&(df['round']==gw)]['opponent_team'].values[0]\n",
    "                is_second=True\n",
    "\n",
    "            opps.append((gw,opp))\n",
    "        cap_opponents[cap]=opps\n",
    "    return cap_opponents\n",
    "\n",
    "cap_opponents_1 = cap_fixtures(df1, team_key_2016)\n",
    "cap_opponents_2 = cap_fixtures(df2, team_key_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_assigner(row, cap_opponents, team_key):\n",
    "    '''\n",
    "    for each row finds the captain(s) that are\n",
    "    playing the same opponent that week. As we\n",
    "    know the team the cap plays we can normally\n",
    "    deduce the team the row player plays for. This\n",
    "    is not true in double weeks for the opponent\n",
    "    were they will play two different caps from different\n",
    "    teams and so the team deduction for the row is\n",
    "    non-unique. If no captain is uniquely identified\n",
    "    then np.nan is returned, else the deduced team\n",
    "    of the row player.\n",
    "    '''\n",
    "    gw = row['round']\n",
    "    opp = row['opponent_team']\n",
    "    is_double = row['is_double']\n",
    "    is_second = row['is_second']\n",
    "    cap_matches = []\n",
    "    valid = False\n",
    "    while not valid:\n",
    "        for cap in cap_opponents.keys():\n",
    "            if gw not in [y for y,z in cap_opponents[cap]]:\n",
    "                continue\n",
    "\n",
    "            indicies = [i for i, x in enumerate([y for y,z in cap_opponents[cap]]) if x == gw]\n",
    "            if (is_double==1) and len(indicies)!=2:\n",
    "                continue\n",
    "            elif (is_double==1) and (is_second==0):\n",
    "                cap_opp = cap_opponents[cap][indicies[0]]\n",
    "            elif (is_double==1) and (is_second==1):\n",
    "                cap_opp = cap_opponents[cap][indicies[1]]\n",
    "            elif is_double==0:\n",
    "                cap_opp = cap_opponents[cap][indicies[0]]\n",
    "\n",
    "            if cap_opp[1] == opp:\n",
    "                cap_matches.append(team_key[cap])\n",
    "        if len(cap_matches)==1:\n",
    "            matched_team = cap_matches[0]\n",
    "            valid=True\n",
    "        else:\n",
    "            return np.nan\n",
    "    return matched_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['team']=df1.apply(team_assigner, cap_opponents = cap_opponents_1, team_key = team_key_2016, axis = 1)\n",
    "df2['team']=df2.apply(team_assigner, cap_opponents = cap_opponents_2, team_key = team_key_2017, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_team(row, df):\n",
    "    '''\n",
    "    backward and\n",
    "    forward filling team\n",
    "    data to fill in missing team\n",
    "    data when cap is non-unique.\n",
    "    requires function as ffill cannot\n",
    "    occur between players only within\n",
    "    players. Leaves missing when adjacent\n",
    "    player is different to row player.\n",
    "    '''\n",
    "    i = row.name\n",
    "    player = row['player']\n",
    "    if pd.isnull(row['team'])==True:\n",
    "        #backward filler\n",
    "        if player==df.loc[i-1,'player']:\n",
    "            return df.loc[i-1, 'team']\n",
    "        #forward filler\n",
    "        elif player==df.loc[i+1,'player']:\n",
    "            return df.loc[i+1, 'team']\n",
    "        else:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return row['team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['team']=df1.apply(fill_team, df=df1, axis=1)\n",
    "df2['team']=df2.apply(fill_team, df=df2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['opponent_team']=df1['opponent_team'].apply(lambda x: num_team_2016[x])\n",
    "df2['opponent_team']=df2['opponent_team'].apply(lambda x: num_team_2017[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df1 and df2 are now clean in team columns, but df3 still needs some work. Done sepereratly becuase the merge has already been made and so double game weeks need to be treated differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy names for opposition need to be renamed for coding convienence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently two sets of dummies in df3 that inform the row on the opponent teams that week, one derived from the github database and one from the FPL scrape. The fpl scrape is missing info on players that left the premier league before the scrape. The github data has numbered them alphabeticaly, i.e. ARS is opponent_team_1. So, I drop the fpl opponent data and rename the github columns to make more sence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "opps = [col for col in df3.columns if 'opponent_team' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_full_name(name, intro):\n",
    "    return intro+str(name)\n",
    "\n",
    "rename_dict = {}\n",
    "for key in num_team_2018.keys():\n",
    "    rename_dict[\n",
    "        add_full_name(name=key,\n",
    "                      intro='opponent_team_')\n",
    "               ]=num_team_2018[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dummies=list([add_full_name(col, 'opposition_') for col in rename_dict.values()])\n",
    "\n",
    "df3.drop(old_dummies,axis=1,inplace=True)\n",
    "\n",
    "df3.rename(columns=rename_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_fixtures_3(df, team_key):\n",
    "    '''\n",
    "    Works similarly to cap_fixtures function.\n",
    "    Differences come from the opponent team already\n",
    "    being dummied and unique gameweeks.\n",
    "    '''\n",
    "    cap_opponents = {}\n",
    "    poss_opp = ['ARS', 'BOU', 'BHA', 'BUR', 'CAR', 'CHE', 'CRY', 'EVE', 'FUL',\n",
    "       'HUD', 'LEI', 'LIV', 'MCI', 'MUN', 'NEW', 'SOU', 'TOT', 'WAT', 'WHU',\n",
    "       'WOL']\n",
    "    for cap in team_key.keys():\n",
    "        #cap = team_key[team]\n",
    "        is_second=False\n",
    "        opps=[]\n",
    "        for gw in df[df['player']==cap]['round'].values:\n",
    "            #all unique due to merge\n",
    "            tmp = df[(df['player']==cap)&(df['round']==gw)]\n",
    "            if tmp['is_double'].values[0]==1:\n",
    "                #double week\n",
    "                dopps=[gw]\n",
    "                for o in poss_opp:\n",
    "                    if tmp[o].values[0]==1:\n",
    "                        dopps.append(o)\n",
    "                dopps = tuple(dopps)\n",
    "                opps.append(dopps)\n",
    "                \n",
    "            elif tmp['is_double'].values[0]==0:\n",
    "                #single week\n",
    "                for o in poss_opp:\n",
    "                    if tmp[o].values[0]==1:\n",
    "                        opps.append((gw,o))\n",
    "                        break\n",
    "        cap_opponents[cap]=opps\n",
    "    return cap_opponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_opponents_3 = cap_fixtures_3(df3, team_key_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_assigner_3(row, cap_opponents, team_key):\n",
    "    '''\n",
    "    matches exactly with captains. Is only\n",
    "    ambiguos when two teams with double\n",
    "    weeks play the same opponents, this never\n",
    "    happens so all good. Overrights original\n",
    "    team data as this is more accurate, original\n",
    "    data was playerwide stat and not measured over\n",
    "    time. So when the player changed team this wasnt\n",
    "    accounted for. This method of matching them with\n",
    "    captains accounts for player movements between teams.\n",
    "    '''\n",
    "    gw = row['round']\n",
    "    poss_opp = ['ARS', 'BOU', 'BHA', 'BUR', 'CAR', 'CHE', 'CRY', 'EVE', 'FUL',\n",
    "       'HUD', 'LEI', 'LIV', 'MCI', 'MUN', 'NEW', 'SOU', 'TOT', 'WAT', 'WHU',\n",
    "       'WOL']\n",
    "    opps=[gw]\n",
    "    for o in poss_opp:\n",
    "        if row[o]==1:\n",
    "            opps.append(o)\n",
    "    opps = tuple(opps)\n",
    "    for cap in cap_opponents.keys():\n",
    "        cap_gws = [tup[0] for tup in cap_opponents[cap]]\n",
    "        if gw in cap_gws:\n",
    "            i = cap_gws.index(gw)\n",
    "            opp_to_match = cap_opponents[cap][i]\n",
    "            if opps == opp_to_match:\n",
    "                team = team_key[cap]\n",
    "                return team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['team1']=df3.apply(team_assigner_3, cap_opponents=cap_opponents_3, team_key=team_key_2018, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['team']=df3['team1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df1, df2 and df3 have complete team data now. They are still missing position data. \n",
    "\n",
    "\n",
    "For df1 and df2 player positions known in df3 can be matched and assigned. When player is not in df3 the only way to know their position is to infer it with the points they get for actions within game. E.g. midfielders get 5 points for a goal while forwards get 4, defenders and goalkeepers get 6. Therefore, if the player gets a goal we can infer their positon from the total points they get, for defenders and goalkeepers we can distinguish by goals becuase no goalkeeper has scoared in the last 3 seasons outside a penalty (https://sabotagetimes.com/sport/the-5-greatest-premiership-goals-scored-by-keepers). This is 1 of 4 freatures we can use to identify positions. We can identify by using:\n",
    "\n",
    "1) goals\n",
    "\n",
    "2) saves\n",
    "\n",
    "3) goals conceded\n",
    "\n",
    "4) clean sheets\n",
    "\n",
    "df3 cannot use this inference on double weeks as saves and goals conceded add/subtract less than one point within a game but not between games. It takes 3 saves to gain a point and 2 goals concende to lose a point for goalkeepers within a game.\n",
    "\n",
    "I do assume that the rules for points hasnt changed over the last three years.\n",
    "\n",
    "If a player identifies their position in one game throughtout their entire observed career all missing positonal data is filled with the identified position. This is safe as FPL keeps constant positions for players no matter what position they actually play in a game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict = {}\n",
    "for player in df3['player'].unique():\n",
    "    pos = df3[df3['player']==player]['position'].unique()[0]\n",
    "    position_dict[player]=pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_fill(row, position_dict):\n",
    "    if row['player'] in position_dict.keys():\n",
    "        return position_dict[row['player']]\n",
    "    else:\n",
    "        return 'unkown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['position']=df1.apply(position_fill, position_dict=position_dict, axis=1)\n",
    "df2['position']=df2.apply(position_fill, position_dict=position_dict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_points(row, position):\n",
    "    points = 0\n",
    "    if row['minutes']>=60:\n",
    "        points += 2 #playing more than 60\n",
    "    elif (row['minutes']>0) and (row['minutes']<60):\n",
    "        points += 1 #playing up to 60 mins\n",
    "    points += row['assists']*3 #assists\n",
    "    points += row['penalties_saved']*5 #penalties saved\n",
    "    points += row['bonus']*1 #bonus points\n",
    "    points -= row['penalties_missed']*2 #penalties missed\n",
    "    points -= row['yellow_cards']*1 #yellow card\n",
    "    points -= row['red_cards']*3 #red card\n",
    "    points -= row['own_goals']*2 #own goals\n",
    "    if position == 'Goalkeeper':\n",
    "        points += row['goals_scored']*6 #goals scored\n",
    "        points += row['clean_sheets']*4 #clean sheet\n",
    "        points += int(row['saves']*(1/3)) #saves made\n",
    "        points -= int(row['goals_conceded']*(1/2)) #goals conceded\n",
    "    elif position == 'Defender':\n",
    "        points += row['goals_scored']*6 #goals scored\n",
    "        points += row['clean_sheets']*4 #clean sheet\n",
    "        points -= int(row['goals_conceded']*(1/2)) #goals conceded\n",
    "    elif position == 'Midfielder':\n",
    "        points += row['goals_scored']*5 #goals scored\n",
    "        points += row['clean_sheets']*1 #clean sheet\n",
    "    elif position == 'Forward': #Forward\n",
    "        points += row['goals_scored']*4 #goals scored\n",
    "    return points\n",
    "\n",
    "def position_assignment(row):\n",
    "    positions = ['Goalkeeper', 'Defender', 'Midfielder', 'Forward']\n",
    "    points = [calculate_points(row, position) for position in positions]\n",
    "    check = []\n",
    "    for p in points:\n",
    "        if p == row['total_points']:\n",
    "            check.append(True)\n",
    "        else:\n",
    "            check.append(False)\n",
    "            \n",
    "    if check.count(True) == 1: #only return non-ambiguos positions\n",
    "        #correction, defenders and gk are ambiguos when no saves \n",
    "        #are made. They are dealt with later in fill_p_pos().\n",
    "        i = check.index(True)\n",
    "        return positions[i]\n",
    "    else:\n",
    "        return 'unkown'\n",
    "\n",
    "def position_safe_ovwr(row, safe_double=True):\n",
    "    if (safe_double==False) and (row['is_double']==1):\n",
    "        return row['position']\n",
    "    infer_pos = position_assignment(row)\n",
    "    if (row['position']=='unkown') or pd.isnull(row['position']):\n",
    "        return infer_pos\n",
    "    else:\n",
    "        return row['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['position']=df1.apply(position_safe_ovwr, axis = 1)\n",
    "df2['position']=df2.apply(position_safe_ovwr, axis = 1)\n",
    "df3['position']=df3.apply(position_safe_ovwr, safe_double = False, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_p_pos(df):\n",
    "    player_positions = {}\n",
    "    for player in df['player'].unique():\n",
    "        tmp = df[df['player']==player]\n",
    "        pos_set = set(tmp['position'].values)\n",
    "        #if results will be unkown and some other pos:\n",
    "        if len(pos_set)==2:\n",
    "            if 'unkown' not in pos_set:\n",
    "                print(player, pos_set)\n",
    "            elif 'Goalkeeper' in pos_set:\n",
    "                player_positions[player]='Goalkeeper'\n",
    "            elif 'Defender' in pos_set:\n",
    "                player_positions[player]='Defender'\n",
    "            elif 'Midfielder' in pos_set:\n",
    "                player_positions[player]='Midfielder'\n",
    "            else: #Forward\n",
    "                player_positions[player]='Forward'\n",
    "                \n",
    "        #should not occur there to test\n",
    "        elif len(pos_set)>3:\n",
    "            print(player, pos_set)\n",
    "        #no unkowns player position was not \n",
    "        #infered or they distinguished themselves\n",
    "        #everygame\n",
    "        else:\n",
    "            player_positions[player]=pos_set.pop()\n",
    "    return player_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_1 = fill_p_pos(df1)\n",
    "pos_2 = fill_p_pos(df2)\n",
    "pos_3 = fill_p_pos(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionaries pos_# contain the position of a player if known or the position infered if unkown and so will not overwrite player position when applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['position']=df1.apply(lambda x: pos_1[x['player']], axis=1)\n",
    "df2['position']=df2.apply(lambda x: pos_2[x['player']], axis=1)\n",
    "df3['position']=df3.apply(lambda x: pos_3[x['player']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional data is now present in all dataframes.\n",
    "\n",
    "Now comes a little cleaning/feature engineering on team scores and leage points. Currently df3 has score (as a string) and the goal difference of a game (team - opponent). df1 and df2 only have the scores for the home and away team. All three dfs need to be cleaned to have scores for team and oppponent and goal difference. \n",
    "\n",
    "Further the league points of a team can be calculated, where a lose = 0, draw = 1 and win = 3. This is cumulative over the season and captains will be again used to caluculate the cumalitive points for the team.\n",
    "\n",
    "Again df3 will need to be treated slightly differently for different cleaning goals, and different data structure (already grouped by weeks so double weeks are a concern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(row, team=True):\n",
    "    home = row['was_home']\n",
    "    if home==team:\n",
    "        score = row['team_h_score']\n",
    "    else:\n",
    "        score = row['team_a_score']\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['team_score']=df1.apply(get_scores, axis=1)\n",
    "df1['opp_score']=df1.apply(get_scores, team=False, axis=1)\n",
    "df2['team_score']=df2.apply(get_scores, axis=1)\n",
    "df2['opp_score']=df2.apply(get_scores, team=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_league_points(row):\n",
    "    if row['team_score']>row['opp_score']:\n",
    "        return 3\n",
    "    elif row['team_score']==row['opp_score']:\n",
    "        return 1\n",
    "    elif row['team_score']<row['opp_score']:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['league_points']=df1.apply(get_league_points,axis=1)\n",
    "df2['league_points']=df2.apply(get_league_points,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_table_1 = {}\n",
    "for cap in team_key_2016.keys():\n",
    "    p_list = df1[df1['player']==cap]['league_points'].values\n",
    "    gw_list = df1[df1['player']==cap]['round'].values\n",
    "    point_table_1[team_key_2016[cap]]=list(zip(gw_list,np.cumsum(p_list)))\n",
    "\n",
    "point_table_2 = {}\n",
    "for cap in team_key_2017.keys():\n",
    "    p_list = df2[df2['player']==cap]['league_points'].values\n",
    "    gw_list = df2[df2['player']==cap]['round'].values\n",
    "    \n",
    "    point_table_2[team_key_2017[cap]]=list(zip(gw_list,np.cumsum(p_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_points(row, point_table):\n",
    "    '''\n",
    "    point tables are applied to players\n",
    "    from the rows gw and team.\n",
    "    '''\n",
    "    gw = row['round']\n",
    "    is_second = row['is_second']\n",
    "    is_double = row['is_double']\n",
    "    team = row['team']\n",
    "    if is_double==0:\n",
    "        i = [gw for gw,p in point_table[team]].index(gw)\n",
    "        points = point_table[team][i]\n",
    "        \n",
    "    else:\n",
    "        i = [i for i,x in enumerate(\n",
    "            [gw for gw,p in point_table[team]]\n",
    "        ) if x==gw] #find indexes of gws of row\n",
    "        if is_second==0:\n",
    "            points = point_table[team][i[0]]\n",
    "        else:\n",
    "            points = point_table[team][i[1]]\n",
    "    return points[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['league_points_cum']=df1.apply(cum_points, point_table=point_table_1, axis=1)\n",
    "df2['league_points_cum']=df2.apply(cum_points, point_table=point_table_2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_3(row, df, team=True):\n",
    "    '''\n",
    "    using the same method as for df1 and df2\n",
    "    but robust to double weeks.\n",
    "    '''\n",
    "    home=row['was_home']\n",
    "    team_a=row['team_a_score']\n",
    "    team_h=row['team_h_score']\n",
    "    is_double=row['is_double']\n",
    "    i = row.name\n",
    "    if i != 0:\n",
    "        #not a double game week in first\n",
    "        #row so safe to filter out\n",
    "        if df.loc[i-1, 'is_double']==1:\n",
    "            prev_is_double=1\n",
    "        elif df.loc[i-1, 'is_double']==0:\n",
    "            prev_is_double=0\n",
    "    if is_double==0:\n",
    "        if home == team:\n",
    "            score = team_h\n",
    "        else:\n",
    "            score = team_a\n",
    "    else:\n",
    "        if prev_is_double == 0:#get first game\n",
    "            if home[0] == team:\n",
    "                score = int(team_h[0])\n",
    "            else:\n",
    "                score = int(team_a[0])\n",
    "        elif prev_is_double == 1:#get second game\n",
    "            if home[1] == team:\n",
    "                score = int(team_h[1])\n",
    "            else:\n",
    "                score = int(team_a[1])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['team_score']=df3.apply(get_scores_3, df=df3, axis=1)\n",
    "df3['opp_score']=df3.apply(get_scores_3, df=df3, team=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome(team, opp):\n",
    "    if team>opp:\n",
    "        return 3\n",
    "    elif team<opp:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def team_league_points_3(row, df):\n",
    "    home=row['was_home']\n",
    "    team_a=row['team_a_score']\n",
    "    team_h=row['team_h_score']\n",
    "    is_double=row['is_double']\n",
    "    i=row.name\n",
    "    if i != 0:\n",
    "        if df.loc[i-1,'is_double']==1:\n",
    "            prev_is_double=1\n",
    "        elif df.loc[i-1,'is_double']==0:\n",
    "            prev_is_double=0\n",
    "    if is_double==0:\n",
    "        if home==True:\n",
    "            points = outcome(team_h,team_a)\n",
    "        elif home==False:\n",
    "            points = outcome(team_a,team_h)\n",
    "    else:\n",
    "        if prev_is_double==0:\n",
    "            if home[0]==True:\n",
    "                points = outcome(team_h[0],team_a[0])\n",
    "            elif home[0]==False:\n",
    "                points = outcome(team_a[0],team_h[0])\n",
    "        elif prev_is_double==1:\n",
    "            if home[1]==True:\n",
    "                points = outcome(team_h[1],team_a[1])\n",
    "            elif home[1]==False:\n",
    "                points = outcome(team_a[1],team_h[1])\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['league_points']=df3.apply(team_league_points_3,df=df3,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_table_3 = {}\n",
    "for cap in team_key_2018.keys():\n",
    "    p_list = df3[df3['player']==cap]['league_points'].values\n",
    "    gw_list = df3[df3['player']==cap]['round'].values\n",
    "    \n",
    "    point_table_3[team_key_2018[cap]]=list(zip(gw_list,np.cumsum(p_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_points_3(row, point_table):\n",
    "    #not entirely sure this is neccessery\n",
    "    #not working\n",
    "    gw = row['round']\n",
    "    team = row['team']\n",
    "    \n",
    "    i = [r for r,p in point_table[team]].index(gw)\n",
    "    \n",
    "    points = point_table[team][i]\n",
    "    \n",
    "    return points[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['league_points_cum']=df3.apply(cum_points_3, point_table=point_table_3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that team data is cleaned, kickoff data is next. While the exact time of the kickoff is informative I will only be using a dummy for if late or not, if kickoff is after 6pm then the game is late (1) else early (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_late(kickoff):\n",
    "    if int(kickoff[-5:-3])>18:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['is_late']=df1['kickoff_time_formatted'].apply(is_late)\n",
    "df2['is_late']=df2['kickoff_time_formatted'].apply(is_late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_late_3(row):\n",
    "    if row['is_double']==1:\n",
    "        kickoff = row['kickoff_time_formatted'][7:9]\n",
    "        try:\n",
    "            kickoff = int(kickoff)\n",
    "        except:\n",
    "            kickoff = int(kickoff[1:])\n",
    "        if kickoff>18:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif row['is_double']==0:\n",
    "        first = row['kickoff_time_formatted'][7:9]\n",
    "        second = row['kickoff_time_formatted'][-12:-10]\n",
    "        try:\n",
    "            first = int(first)\n",
    "        except:\n",
    "            first = int(first[1:])\n",
    "        try:\n",
    "            second = int(second)\n",
    "        except:\n",
    "            second = int(second[1:])\n",
    "        if (first>18)&(second>18):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['is_late']=df3.apply(is_late_3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally, I group 2016/17 and 2017/19 by gameweek so that each row represent a single week rather than a game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop=['Unnamed: 0', 'ea_index', 'element', 'id', 'kickoff_time',\n",
    "        'kickoff_time_formatted', 'loaned_in', 'loaned_out',\n",
    "        'team_a_score', 'team_h_score', 'is_second', 'league_points']\n",
    "\n",
    "constants=['selected', 'transfers_balance', 'transfers_in', 'transfers_out',\n",
    "          'value', 'player', 'is_double', 'team', 'position', 'round']\n",
    "take_last = ['league_points_cum']\n",
    "rules=['is_late', 'was_home']\n",
    "to_mean = ['bps', 'minutes', 'saves']\n",
    "to_dummy=['opponent_team']\n",
    "to_sum=[col for col in df1.columns if col not in (to_drop+constants+rules+to_mean+to_dummy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan1=pd.get_dummies(df1, columns=to_dummy, prefix='',prefix_sep='')\n",
    "pan2=pd.get_dummies(df2, columns=to_dummy, prefix='',prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_make(alist):\n",
    "    alist = [e for e in alist]\n",
    "    return alist[0]\n",
    "\n",
    "def is_late_group(alist):\n",
    "    if 1 in alist:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def was_home_group(alist):\n",
    "    if True in alist:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def create_agg(df, opp_teams, constants=constants, rules=rules, to_mean=to_mean, to_sum=to_sum):\n",
    "    agg={}\n",
    "    for constant in constants:\n",
    "        agg[constant]=constant_make\n",
    "    for mean_me in to_mean:\n",
    "        agg[mean_me]='mean'\n",
    "    for sum_me in to_sum+opp_teams:\n",
    "        agg[sum_me]='sum'\n",
    "    for rule in rules:\n",
    "        if rule=='is_late':\n",
    "            agg[rule]=is_late_group\n",
    "        else:\n",
    "            agg[rule]=was_home_group\n",
    "    \n",
    "    #league_points\n",
    "    agg['league_points_cum']='max'\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_1 = create_agg(pan1, opp_teams=teams_2016)\n",
    "agg_2 = create_agg(pan2, opp_teams=teams_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan1.drop(to_drop, axis = 1, inplace = True)\n",
    "pan2.drop(to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan1=pan1.groupby(['player', 'round']).agg(agg_1)\n",
    "pan2=pan2.groupby(['player', 'round']).agg(agg_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_drop=['element','ea_index','id','kickoff_time','kickoff_time_formatted',\n",
    "         'loaned_in','loaned_out','team_a_score','team_h_score','league_points',\n",
    "         'order','team1']\n",
    "pan3=df3.drop(df3_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAST THING!!! The was_home dummy is still in True False format, it needs to be in 1 0 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def was_home_num(was_home):\n",
    "    if was_home == False:\n",
    "        return 0\n",
    "    elif was_home == True:\n",
    "        return 1\n",
    "    else:\n",
    "        return was_home #some are already num\n",
    "    \n",
    "\n",
    "pan1['was_home']=pan1['was_home'].apply(was_home_num)\n",
    "pan2['was_home']=pan2['was_home'].apply(was_home_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def was_home_num_3(was_home):\n",
    "    if type(was_home)==list:\n",
    "        if True in was_home:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if was_home==True:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "pan3['was_home']=pan3['was_home'].apply(was_home_num_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop=[col for col in pan3.columns if '_y' in col]\n",
    "also_drop=[\n",
    "    'gw',\n",
    "    'pts',\n",
    "    'mins',\n",
    "    'goals',\n",
    "    'clean',\n",
    "    'conceded',\n",
    "    'pen_saved',\n",
    "    'pen_missed',\n",
    "    'yellows',\n",
    "    'red',\n",
    "    'bonus_sys',\n",
    "    'net_transfers',\n",
    "    'selected_by',\n",
    "    'fixture_difficulty',\n",
    "    'is_home',\n",
    "    'score'\n",
    "]\n",
    "pan3.drop(to_drop+also_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan1.to_csv('cleaned_pan1.csv')\n",
    "pan2.to_csv('cleaned_pan2.csv')\n",
    "pan3.to_csv('cleaned_pan3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['key_0',\n",
       " 'Unnamed: 0',\n",
       " 'assists',\n",
       " 'attempted_passes',\n",
       " 'big_chances_created',\n",
       " 'big_chances_missed',\n",
       " 'bonus',\n",
       " 'bps',\n",
       " 'clean_sheets',\n",
       " 'clearances_blocks_interceptions',\n",
       " 'completed_passes',\n",
       " 'creativity',\n",
       " 'dribbles',\n",
       " 'errors_leading_to_goal',\n",
       " 'errors_leading_to_goal_attempt',\n",
       " 'fouls',\n",
       " 'goals_conceded',\n",
       " 'goals_scored',\n",
       " 'ict_index',\n",
       " 'influence',\n",
       " 'key_passes',\n",
       " 'minutes',\n",
       " 'offside',\n",
       " 'open_play_crosses',\n",
       " 'own_goals',\n",
       " 'penalties_conceded',\n",
       " 'penalties_missed',\n",
       " 'penalties_saved',\n",
       " 'recoveries',\n",
       " 'red_cards',\n",
       " 'round',\n",
       " 'saves',\n",
       " 'selected',\n",
       " 'tackled',\n",
       " 'tackles',\n",
       " 'target_missed',\n",
       " 'threat',\n",
       " 'total_points',\n",
       " 'transfers_balance',\n",
       " 'transfers_in',\n",
       " 'transfers_out',\n",
       " 'value',\n",
       " 'was_home',\n",
       " 'winning_goals',\n",
       " 'yellow_cards',\n",
       " 'player',\n",
       " 'ARS',\n",
       " 'BOU',\n",
       " 'BHA',\n",
       " 'BUR',\n",
       " 'CAR',\n",
       " 'CHE',\n",
       " 'CRY',\n",
       " 'EVE',\n",
       " 'FUL',\n",
       " 'HUD',\n",
       " 'LEI',\n",
       " 'LIV',\n",
       " 'MCI',\n",
       " 'MUN',\n",
       " 'NEW',\n",
       " 'SOU',\n",
       " 'TOT',\n",
       " 'WAT',\n",
       " 'WHU',\n",
       " 'WOL',\n",
       " 'is_double',\n",
       " 'team',\n",
       " 'position',\n",
       " 'form',\n",
       " 'report',\n",
       " 'score_diff',\n",
       " 'team_score',\n",
       " 'opp_score',\n",
       " 'league_points_cum',\n",
       " 'is_late']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pan3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pan3['player'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
