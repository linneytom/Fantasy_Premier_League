{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import Ridge, LogisticRegression, Lasso, ElasticNet, LinearRegression\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from sklearn.svm import SVR, SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import json\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes/Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FootballPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    preprocessor class, dropsmissing, dummies, polynomials, assigns class to target,\n",
    "    takes target out of dataset, gets coeficient names and makes the train test split\n",
    "    \n",
    "        target: str of target column\n",
    "        to_drop: list of columns to drop\n",
    "        to_dummy: list of columns to dummy\n",
    "        test_size: testset as fraction as total dataset\n",
    "        dropna: bool, True drops rows with np.nan values, default is True\n",
    "        classify: bool, True uses the assign class function and stratifys the train test split\n",
    "                  designed for processing data for classifiers\n",
    "        threshold: int, if y>int return 1. used to create the classes in the target.\n",
    "        poly: bool, True returns dataset with 2-degree polynomials of original dataset\n",
    "              the coef_names are adjusted to fit the new number of features.\n",
    "    '''\n",
    "    def __init__(self, target, to_drop=None, to_dummy=None, test_size=0.3, dropna=True, classify=False, threshold=None, poly=False, time_split=False,when=77):\n",
    "        self.to_drop=to_drop\n",
    "        self.to_dummy=to_dummy\n",
    "        self.test_size=test_size\n",
    "        self.target=target\n",
    "        self.dropna=dropna\n",
    "        self.classify=classify\n",
    "        self.threshold=threshold\n",
    "        self.poly=poly\n",
    "        self.time_split=time_split\n",
    "        self.when=when\n",
    "        \n",
    "    def fill_missing_teams(self, X):\n",
    "        '''\n",
    "        fills missing values with 0\n",
    "        for teams that cross from train to \n",
    "        test set but might not be in all seasons\n",
    "        '''\n",
    "        teams=['ARS', 'BOU', 'BHA', 'BUR', 'CHE', 'CRY', 'EVE','NEW',\n",
    "        'HUD', 'LEI', 'LIV', 'MCI', 'MUN', 'SOU', 'TOT', 'WAT',\n",
    "       'WHU']\n",
    "        for team in teams:\n",
    "            try:\n",
    "                X[team]=X[team].fillna(value=0)\n",
    "            except:\n",
    "                continue\n",
    "        return X\n",
    "        \n",
    "    def dropmissing(self, X):\n",
    "        '''\n",
    "        drops missing values, for the designed data set this will\n",
    "        take out rows without lags. removing the first 2 weeks for\n",
    "        each player\n",
    "        '''\n",
    "        X.dropna(inplace=True)\n",
    "        return X\n",
    "        \n",
    "    def get_target(self, X):\n",
    "        '''\n",
    "        pops out target creating a y series\n",
    "        '''\n",
    "        y=X.pop(target)\n",
    "        return X,y\n",
    "        \n",
    "    def drop_me(self, X):\n",
    "        '''\n",
    "        drops any columns specified\n",
    "        '''\n",
    "        droping=self.to_drop\n",
    "        X=X.drop(droping, axis=1)\n",
    "        return X\n",
    "    \n",
    "    def dummy_me(self, X):\n",
    "        '''\n",
    "        dummies any columns specified if position\n",
    "        or team so doesnt drop first as unkowns \n",
    "        and dropout teams will be force\n",
    "        dropped later\n",
    "        '''\n",
    "        if ('position' in self.to_dummy) or ('team' in self.to_dummy):\n",
    "            dummying = [col for col in self.to_dummy if (col!='position') and (col!='team')]\n",
    "            X=pd.get_dummies(X,columns=dummying,drop_first=True)\n",
    "            \n",
    "            if 'position' in self.to_dummy:\n",
    "                X=pd.get_dummies(X,columns=['position'])\n",
    "                \n",
    "            if 'team' in self.to_dummy:\n",
    "                X=pd.get_dummies(X,columns=['team'])\n",
    "        else:\n",
    "            dummying=self.to_dummy\n",
    "            X=pd.get_dummies(X,columns=dummying)\n",
    "        return X\n",
    "    \n",
    "    def polyfi(self, X):\n",
    "        '''\n",
    "        creates the polynomial of the X features, also gets the coef names\n",
    "        returns both. no keyword for more than 2 degrees\n",
    "        '''\n",
    "        poly=PolynomialFeatures()#2degrees\n",
    "        coef_names=poly.fit(X).get_feature_names(X.columns)\n",
    "        coef_names=[col.replace(' ', '_x_') for col in coef_names]\n",
    "        X=poly.fit_transform(X)\n",
    "        X=pd.DataFrame(X,columns=coef_names)\n",
    "        return X\n",
    "    \n",
    "    def assign_class(self, row):\n",
    "        '''\n",
    "        The .apply function used to classifiy the target\n",
    "        '''\n",
    "        if row > self.threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def create_class(self, y):\n",
    "        '''\n",
    "        function that employs the .apply function to classify y\n",
    "        '''\n",
    "        y = y.apply(self.assign_class)\n",
    "        return y\n",
    "    \n",
    "    def get_coef_names(self, X):\n",
    "        '''\n",
    "        gets coef names for X features\n",
    "        '''\n",
    "        return X.columns\n",
    "    \n",
    "    def train_test(self, X, y):\n",
    "        '''\n",
    "        makes train test split, if classify == True then uses stratify.\n",
    "        '''\n",
    "        if self.classify==True:\n",
    "            return train_test_split(X,y,test_size=self.test_size,stratify=y,random_state=1)\n",
    "        else:\n",
    "            return train_test_split(X,y,test_size=self.test_size)\n",
    "    \n",
    "    def make_time_split(self, X, y):\n",
    "        '''\n",
    "        default=adj_round 77\n",
    "        makes the test set the 2018/19 season\n",
    "        the train set is the 2016/17 and 2017/18 season\n",
    "        '''\n",
    "        \n",
    "        print('X', X.shape)\n",
    "        \n",
    "        X_test = X[X['adj_round']>=self.when]\n",
    "        \n",
    "        X_train = X[X['adj_round']<self.when]\n",
    "        \n",
    "        train_loc = list(X_train.index)\n",
    "        test_loc = list(X_test.index)\n",
    "        y_train = y.loc[train_loc]\n",
    "        y_test = y.loc[test_loc]\n",
    "        \n",
    "        X_train=X_train.drop('adj_round', axis=1)\n",
    "        X_test=X_test.drop('adj_round', axis=1)\n",
    "        \n",
    "        print('X_train',X_train.shape)\n",
    "        print('X_test',X_test.shape)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def drop_unkowns(self, X):\n",
    "        X = X.drop('position_unkown',axis=1)\n",
    "        return X\n",
    "    \n",
    "    def clear_dummies(self, X):\n",
    "        drop_dummies=['STO', 'FUL', 'SWA', 'MID', \n",
    "        'SUN', 'WOL', 'WBA', 'CAR', 'HUL','unkown']\n",
    "        to_stay=X.columns\n",
    "        \n",
    "        for dum in drop_dummies:\n",
    "            to_stay=[col for col in to_stay if dum not in col]\n",
    "        \n",
    "        to_drop=[col for col in X.columns if col not in to_stay]\n",
    "        X=X.drop(to_drop,axis=1)\n",
    "        return X\n",
    "            \n",
    "            \n",
    "    \n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        channels different inputs to the right functions. \n",
    "        returns train test split data and the coef_names\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.to_drop != None:\n",
    "            X=self.drop_me(X)\n",
    "            \n",
    "            \n",
    "        if self.to_dummy != None:\n",
    "            X=self.dummy_me(X)\n",
    "            X=self.clear_dummies(X)\n",
    "            \n",
    "        X=self.fill_missing_teams(X)\n",
    "        \n",
    "        \n",
    "        if self.dropna==True:\n",
    "            X=self.dropmissing(X)\n",
    "            \n",
    "        \n",
    "        \n",
    "       # if 'position' in self.to_dummy:\n",
    "          #  X = self.drop_unkowns(X)\n",
    "            \n",
    "        X,y=self.get_target(X)\n",
    "        \n",
    "        if self.poly==True:\n",
    "            X = self.polyfi(X)\n",
    "            \n",
    "        if self.classify == True:\n",
    "            y=self.create_class(y)\n",
    "        \n",
    "        \n",
    "            \n",
    "        if self.time_split==False:\n",
    "            X_train, X_test, y_train, y_test = self.train_test(X,y)\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = self.make_time_split(X,y)\n",
    "        \n",
    "        coef_names=self.get_coef_names(X_train)\n",
    "            \n",
    "        return X_train, X_test, y_train, y_test, coef_names\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "class ClassifyPlayers(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    runs a classification model and any other processes specified by parameters\n",
    "    \n",
    "        model: unfitted model object if train set, fitted if test.\n",
    "        test: bool, True for test set data. if True then no gridsearch or fitting takes place.\n",
    "              just returns the score of the model on the test set and the predicted probabilites\n",
    "        params: dict, used in gridsearch, specific to model\n",
    "        scale_fit: the scale_fit attribute from standardscaler on a fit_transform of the train\n",
    "                   needed for test set\n",
    "        mean_fit: the mean_fit attribute from the standardscaler on a fit_transform of the train\n",
    "                  needed for the test set\n",
    "        balance: \"under\", \"over\", \"smote\", \"adasyn\", default None. Specify the imbalance fix method\n",
    "                 under uses bagging with undersampling boostrapped samples. over takes a random over\n",
    "                 sampler of the data set and trains the model on that, the score is on the original\n",
    "                 dataset. smote does the same as over but with the smote algorithm. adasyn does a\n",
    "                 grid search for the optimal neighbors and a inner gridsearch for the optimal model \n",
    "                 for each neighbor, takes a very long time. once the optimal model and neighbors are\n",
    "                 found the model is fitted on the resampled data. The score is on the original data.\n",
    "        bag: bool, if True then a bagging classifier is used. User cannot input params for this bag\n",
    "             without editing code in class. Uses the best estimator from gridsearch as the base\n",
    "        boost: bool, if True then a adaboost is used. Uses the best etstimator fro the gridsearch\n",
    "               as the base.\n",
    "        reduce:float(>0), 0 will perform pca on columns and keep components = columns, None will not\n",
    "               use pca. 0.3 will reduce the components to cols/1.3. So 1 will half the features of the \n",
    "               model.\n",
    "        fit_pca: fitted pca object, used for test data.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, model, balance=None, params=None, test=False, scale_fit=None, mean_fit=None, fp_tol=None, bag=False, boost=False, reduce=None, fit_pca=None, n_jobs=1,balparams=None):\n",
    "        self.model = model\n",
    "        self.test = test\n",
    "        self.params=params\n",
    "        self.scale_fit = scale_fit\n",
    "        self.mean_fit = mean_fit\n",
    "        #self.classification_thresh = classification_thresh 0.5\n",
    "        #self.fp_tol = fp_tol None\n",
    "        self.balance = balance\n",
    "        self.bag=bag\n",
    "        self.boost=boost\n",
    "        self.reduce=reduce\n",
    "        self.fit_pca=fit_pca\n",
    "        self.n_jobs=n_jobs\n",
    "        self.balparams=balparams\n",
    "    \n",
    "    def standardize(self, X):\n",
    "        '''\n",
    "        standardizes the data, fits and transforms train\n",
    "        data, transforms test data. returns a numpy array\n",
    "        '''\n",
    "        scaler = StandardScaler()\n",
    "        if self.test == False:\n",
    "            X=scaler.fit_transform(X)\n",
    "            return X\n",
    "        else:\n",
    "            scaler.scale_=self.scale_fit\n",
    "            scaler.mean_=self.mean_fit\n",
    "            X=scaler.transform(X)\n",
    "            return X\n",
    "        \n",
    "    def find_hyper_params(self, X, y):\n",
    "        '''\n",
    "        gridsearches the X,y dataset to find optimal\n",
    "        hyper params. Uses precision as a score metric.\n",
    "        returns best_estimator\n",
    "        '''\n",
    "        gs = GridSearchCV(self.model, self.params,\n",
    "                         cv=StratifiedKFold(n_splits=5, shuffle=True),\n",
    "                         n_jobs=self.n_jobs,verbose=1,scoring='precision')\n",
    "        gs.fit(X,y)\n",
    "        return gs.best_estimator_\n",
    "    \n",
    "    def balance_bag_grid(self, X, y):\n",
    "        '''\n",
    "        gridsearches on the balanced bagging classifier.\n",
    "        used on imbalanced datasets. params cannot be set\n",
    "        outside the code and returns the best_estimator.\n",
    "        '''\n",
    "        self.model = BalancedBaggingClassifier(self.model, n_estimators=200,\n",
    "                                                      boostrap=True, n_jobs=self.n_jobs,\n",
    "                                                      verbose=1)\n",
    "        params_imb={\n",
    "            'max_samples':[1.0,0.7,0.5,0.3],\n",
    "            'sampling_strategy':[1.0, 0.6, 0.3],\n",
    "            'replacement':[True]\n",
    "        }\n",
    "        gs=GridSearchCV(self.model, params_imb, cv=StratifiedKFold(n_splits=5, shuffle=True),\n",
    "                        verbose=1, scoring='precision')\n",
    "        gs.fit(X,y)\n",
    "        return gs.best_estimator_\n",
    "    \n",
    "    def bag_me(self):\n",
    "        '''\n",
    "        bags and then gridsearches on the base estimator\n",
    "        returns the best bagged estimator. Doesnt\n",
    "        use find_hyper_params() becuasue need best_score_\n",
    "        attribute from the GridSearchCV()\n",
    "        '''\n",
    "        bagged_model=BaggingClassifier(base_estimator=self.model,\n",
    "                                    n_estimators=200,\n",
    "                                    n_jobs=self.n_jobs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return bagged_model\n",
    "        \n",
    "    \n",
    "    def boost_me(self):\n",
    "        '''\n",
    "        boosts the base estimator and returns the\n",
    "        boosted model\n",
    "        '''\n",
    "        boosted_model=AdaBoostClassifier(base_estimator=self.model,\n",
    "                                     n_estimators=100)\n",
    "        return boosted_model\n",
    "    \n",
    "    def pca_me(self, X):\n",
    "        '''\n",
    "        if train fits and transforms a pca decomposition onto the\n",
    "        dataset using the reduction ratio specified in object initilization.\n",
    "        returns decomposed and reduced data aswell as the pca object\n",
    "        \n",
    "        if test uses the pca object specified in initilization and\n",
    "        transforms the test set with it. returns the decomposed and reduced\n",
    "        data aswell as the pca object\n",
    "        '''\n",
    "        if self.test==False:\n",
    "            self.reduce+=1\n",
    "            ncom=int(len(X)//self.reduce)\n",
    "            pca = PCA(n_components=ncom)\n",
    "            coef_names=[f'PC_{x}' for x in range(1, pca.n_components+1)]\n",
    "            X = pca.fit_transform(X)\n",
    "        else:\n",
    "            pca = self.fit_pca\n",
    "            X = pca.transform(X)\n",
    "        return X, pca\n",
    "    \n",
    "    def over_samp_grid(self, sampler, X,y):\n",
    "        kf=StratifiedKFold(n_splits=5,shuffle=True)\n",
    "        bal_pipe=make_pipeline_imb(sampler,self.model)\n",
    "        gs=GridSearchCV(bal_pipe,self.balparams,cv=kf,\n",
    "                       n_jobs=self.n_jobs,\n",
    "                       verbose=1,scoring='precision')\n",
    "        gs.fit(X,y)\n",
    "        \n",
    "        return gs.best_estimator_ #opperates like a best model\n",
    "            \n",
    "        \n",
    "            \n",
    "    def transform(self, X,y):\n",
    "        '''\n",
    "        deals with X and y dataset depending on initilization\n",
    "        paramaters. returns score of dataset and predicted probabilities.\n",
    "        if train set also returns coefficient values, a fitted model\n",
    "        object and a fitted pca object, if pca was used.\n",
    "        '''\n",
    "        \n",
    "        params_bag={\n",
    "            'max_samples':[1.0, 0.7, 0.5, 0.3],\n",
    "            'max_features':[1.0, 0.9, 0.5]\n",
    "        }\n",
    "        \n",
    "        params_bag_bal={\n",
    "            'baggingclassifier__max_samples':[1.0, 0.7, 0.5, 0.3],\n",
    "            'baggingclassifier__max_features':[1.0, 0.9, 0.5]\n",
    "        }\n",
    "        \n",
    "        X = self.standardize(X)\n",
    "        \n",
    "        if self.reduce!=None:\n",
    "            X, pca=self.pca_me(X)\n",
    "        \n",
    "        if self.test==False:\n",
    "            if self.balance=='over':\n",
    "                sampler=RandomOverSampler()\n",
    "                self.model=self.over_samp_grid(sampler,X,y)\n",
    "                if self.bag==True:\n",
    "                    self.model=self.bag_me()\n",
    "                    self.params=params_bag_bal\n",
    "                    self.model=self.over_samp_grid(sampler,X,y)\n",
    "                \n",
    "                if self.boost==True:\n",
    "                    self.model=self.boost_me()\n",
    "                \n",
    "                \n",
    "            elif self.balance=='under':\n",
    "                #what is happening here!?!?!\n",
    "                sampler = RandomUnderSampler()\n",
    "                self.model=self.find_hyper_params(X,y)\n",
    "            \n",
    "                self.model=balance_bag_grid(X,y)\n",
    "                self.model.fit(X,y)\n",
    "                \n",
    "            elif self.balance=='smote':\n",
    "                sampler = SMOTE()\n",
    "                self.model=self.over_samp_grid(sampler,X,y)\n",
    "                print(self.model)\n",
    "                if self.bag==True:\n",
    "                    self.model=self.bag_me()\n",
    "                    self.params=params_bag_bal\n",
    "                    self.model=self.over_samp_grid(sampler,X,y)\n",
    "                \n",
    "                if self.boost==True:\n",
    "                    self.model=self.boost_me()\n",
    "                \n",
    "            elif self.balance=='adasyn':\n",
    "                sampler = ADASYN(n_neighbors=20)\n",
    "                self.model=self.over_samp_grid(sampler,X,y)\n",
    "                if self.bag==True:\n",
    "                    self.model=self.bag_me()\n",
    "                    self.params=params_bag_bal\n",
    "                    self.model=self.over_samp_grid(sampler,X,y)\n",
    "                \n",
    "                if self.boost==True:\n",
    "                    self.model=self.boost_me()\n",
    "                \n",
    "            else:\n",
    "                self.model=self.find_hyper_params(X,y)\n",
    "                if self.bag==True:\n",
    "                    self.model=self.bag_me()\n",
    "                    self.params=params_bag\n",
    "                    self.model=self.find_hyper_params(X,y)\n",
    "                \n",
    "                if self.boost==True:\n",
    "                    self.model=self.boost_me()\n",
    "                    \n",
    "                \n",
    "            self.model.fit(X,y)\n",
    "            \n",
    "            \n",
    "            print(np.mean(cross_val_score(self.model, X, y,scoring='precision')))\n",
    "            print(self.model)\n",
    "            try:\n",
    "                if len(self.model.coef_)==1:\n",
    "                    coef = self.model.coef_[0]\n",
    "                else:\n",
    "                    coef = self.model.coef_\n",
    "            except:\n",
    "                \n",
    "                try:\n",
    "                    coef = self.model.feature_importances_\n",
    "                except:\n",
    "                    try:\n",
    "                        coef = self.model.steps[-1][-1].coef_\n",
    "                    except:\n",
    "                        try:\n",
    "                            coef=self.model.steps[-1][-1].feature_importances_\n",
    "                        except:\n",
    "                            coef=np.nan\n",
    "            proba = [x[1] for x in self.model.predict_proba(X)]\n",
    "            try:\n",
    "                return coef, proba, self.model, pca\n",
    "            except:\n",
    "                return coef, proba, self.model\n",
    "        #returns fitted optimal model and optimal threshold\n",
    "        else:\n",
    "            print(np.mean(cross_val_score(self.model, X, y,scoring='precision')))\n",
    "            proba = [x[1] for x in self.model.predict_proba(X)]\n",
    "            return proba\n",
    "        \n",
    "        #returns score from a fitted model\n",
    "    \n",
    "    def fit(self, X,y):\n",
    "        return self\n",
    "    \n",
    "\n",
    "class RegressPlayers(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    runs a classification model and any other processes specified by parameters\n",
    "    \n",
    "        model: unfitted model object if train set, fitted if test.\n",
    "        test: bool, True for test set data. if True then no gridsearch or fitting takes place.\n",
    "              just returns the score of the model on the test set and the predicted probabilites\n",
    "        params: dict, used in gridsearch, specific to model\n",
    "        scale_fit: the scale_fit attribute from standardscaler on a fit_transform of the train\n",
    "                   needed for test set\n",
    "        mean_fit: the mean_fit attribute from the standardscaler on a fit_transform of the train\n",
    "                  needed for the test set\n",
    "        bag: bool, if True then a bagging classifier is used. User cannot input params for this bag\n",
    "             without editing code in class. Uses the best estimator from gridsearch as the base\n",
    "        boost: bool, if True then a adaboost is used. Uses the best etstimator fro the gridsearch\n",
    "               as the base.\n",
    "        reduce:float(>0), 0 will perform pca on columns and keep components = columns, None will not\n",
    "               use pca. 0.3 will reduce the components to cols/1.3. So 1 will half the features of the \n",
    "               model.\n",
    "        fit_pca: fitted pca object, used for test data.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, model, params=None, test=False, scale_fit=None, mean_fit=None, bag=False, boost=False, reduce=None, fit_pca=None, n_jobs=1):\n",
    "        self.model=model\n",
    "        self.params=params\n",
    "        self.test=test\n",
    "        self.scale_fit=scale_fit\n",
    "        self.mean_fit=mean_fit\n",
    "        self.bag=bag\n",
    "        self.boost=boost\n",
    "        self.reduce=reduce\n",
    "        self.fit_pca=fit_pca\n",
    "        self.n_jobs=n_jobs\n",
    "        \n",
    "    def standardize(self, X):\n",
    "        '''\n",
    "        standardizes the data, fits and transforms train\n",
    "        data, transforms test data. returns a numpy array\n",
    "        '''\n",
    "        scaler = StandardScaler()\n",
    "        if self.test == False:\n",
    "            X=scaler.fit_transform(X)\n",
    "            return X\n",
    "        else:\n",
    "            scaler.scale_=self.scale_fit\n",
    "            scaler.mean_=self.mean_fit\n",
    "            X=scaler.transform(X)\n",
    "            return X\n",
    "        \n",
    "    def find_hyper_params(self, X, y):\n",
    "        '''\n",
    "        gridsearches the X,y dataset to find optimal\n",
    "        hyper params. Uses precision as a score metric.\n",
    "        returns best_estimator\n",
    "        '''\n",
    "        gs = GridSearchCV(self.model, self.params,\n",
    "                         cv=KFold(n_splits=5, shuffle=True),\n",
    "                         verbose=1, n_jobs=self.n_jobs)\n",
    "        gs.fit(X,y)\n",
    "        return gs.best_estimator_\n",
    "    \n",
    "    def bag_me(self, X, y):\n",
    "        '''\n",
    "        bags and then gridsearches on the base estimator\n",
    "        returns the best bagged estimator. Doesnt\n",
    "        use find_hyper_params() becuasue need best_score_\n",
    "        attribute from the GridSearchCV()\n",
    "        '''\n",
    "        self.model=BaggingRegressor(base_estimator=self.model,\n",
    "                                    n_estimators=200, n_jobs=self.n_jobs)\n",
    "        \n",
    "        params_bag={\n",
    "            'max_samples':[1.0, 0.7, 0.5],\n",
    "            'max_features':[1.0, 0.9, 0.5]\n",
    "        }\n",
    "        \n",
    "        gs = GridSearchCV(self.model, params_bag,\n",
    "                         cv=KFold(n_splits=5, shuffle=True))\n",
    "        \n",
    "        gs.fit(X,y)\n",
    "        return gs.best_estimator_\n",
    "        \n",
    "    \n",
    "    def boost_me(self, X, y):\n",
    "        '''\n",
    "        boosts the base estimator and returns the\n",
    "        boosted model\n",
    "        '''\n",
    "        boosted_model=AdaBoostRegressor(base_estimator=self.model,\n",
    "                                       n_estimators=500)\n",
    "        return boosted_model\n",
    "    \n",
    "    def pca_me(self, X):\n",
    "        '''\n",
    "        if train fits and transforms a pca decomposition onto the\n",
    "        dataset using the reduction ratio specified in object initilization.\n",
    "        returns decomposed and reduced data aswell as the pca object\n",
    "        \n",
    "        if test uses the pca object specified in initilization and\n",
    "        transforms the test set with it. returns the decomposed and reduced\n",
    "        data aswell as the pca object\n",
    "        '''\n",
    "        if self.test==False:\n",
    "            self.reduce+=1\n",
    "            ncom=int(len(X[0])//self.reduce)\n",
    "            pca = PCA(n_components=ncom)\n",
    "            coef_names=[f'PC_{x}' for x in range(1, pca.n_components+1)]\n",
    "            X = pca.fit_transform(X)\n",
    "        else:\n",
    "            pca = self.fit_pca\n",
    "            X = pca.transform(X)\n",
    "        return X, pca\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        '''\n",
    "        deals with X and y dataset depending on initilization\n",
    "        paramaters. returns score of dataset and predicted probabilities.\n",
    "        if train set also returns coefficient values, a fitted model\n",
    "        object and a fitted pca object, if pca was used.\n",
    "        '''\n",
    "        X = self.standardize(X)\n",
    "        \n",
    "        if self.reduce!=None:\n",
    "            X, pca = self.pca_me(X)\n",
    "        elif (self.fit_pca!=None) and (self.test==True):\n",
    "            X, pca = self.pca_me(X)\n",
    "        \n",
    "        if self.test==False:\n",
    "            \n",
    "            self.model=self.find_hyper_params(X,y)\n",
    "            \n",
    "            if self.bag==True:\n",
    "                self.model=self.bag_me(X, y)\n",
    "            elif self.boost==True:\n",
    "                self.model=self.boost_me(X,y)\n",
    "                \n",
    "            self.model.fit(X,y)\n",
    "            \n",
    "            \n",
    "            print(np.mean(cross_val_score(self.model, X, y)))\n",
    "            print(self.model)\n",
    "            try:\n",
    "                if len(self.model.coef_)==1:\n",
    "                    coef = self.model.coef_[0]\n",
    "                else:\n",
    "                    coef = self.model.coef_\n",
    "                #check if right\n",
    "            except:\n",
    "                try:\n",
    "                    coef = self.model.feature_importances_\n",
    "                except:\n",
    "                    print('coef is empty!')\n",
    "                    coef=[]\n",
    "            pred = self.model.predict(X)\n",
    "            try:\n",
    "                return coef, pred, self.model, pca\n",
    "            except:\n",
    "                return coef, pred, self.model\n",
    "        #returns fitted optimal model and optimal threshold\n",
    "        else:\n",
    "            print(np.mean(cross_val_score(self.model, X, y)))\n",
    "            pred = self.model.predict(X)\n",
    "            return pred\n",
    "    \n",
    "    def fit(self):\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 19)\n",
      "X_train (40949, 18)\n",
      "X_test (16860, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../FPL_Data/linear_data.csv')\n",
    "\n",
    "to_drop=['Unnamed: 0']\n",
    "target='next_week_points'\n",
    "\n",
    "footprep=FootballPreprocessor(target=target, to_drop=to_drop,\n",
    "                             time_split=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test, coef_names = footprep.transform(data)\n",
    "\n",
    "scale_fit=StandardScaler().fit(X_train).scale_\n",
    "mean_fit=StandardScaler().fit(X_train).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done   8 out of  10 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28671106891766357\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
      "         normalize=False)\n",
      "-2.2474795771317744e+19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lin_params={\n",
    "    'fit_intercept':[True,False]\n",
    "}\n",
    "\n",
    "lin_model=LinearRegression()\n",
    "\n",
    "lin_train=RegressPlayers(model=lin_model,\n",
    "                         params=lin_params,\n",
    "                         n_jobs=7)\n",
    "\n",
    "lin_coef, lin_pred_train, lin_opt_model=lin_train.transform(X_train,\n",
    "                                                           y_train)\n",
    "\n",
    "lin_test = RegressPlayers(model=lin_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "lin_pred_test=lin_test.transform(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_model']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lin_opt_model, 'linear_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=7)]: Done  87 out of 100 | elapsed:    1.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2867318188785372\n",
      "Ridge(alpha=46.41588833612782, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "0.2677557427956175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lin_r_params={\n",
    "    'alpha':np.logspace(-5,5,10),\n",
    "    'fit_intercept':[True,False]\n",
    "}\n",
    "\n",
    "lin_model=Ridge()\n",
    "\n",
    "lin_train=RegressPlayers(model=lin_model,\n",
    "                         params=lin_r_params,\n",
    "                         n_jobs=7)\n",
    "\n",
    "lin_coef, lin_pred_train, lin_opt_model=lin_train.transform(X_train,\n",
    "                                                           y_train)\n",
    "\n",
    "lin_test = RegressPlayers(model=lin_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "lin_pred_test=lin_test.transform(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ridge_model']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lin_opt_model, 'ridge_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    3.7s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28671839368387547\n",
      "Lasso(alpha=0.0016681005372000592, copy_X=True, fit_intercept=True,\n",
      "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "0.2678209482614845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lin_l_params={\n",
    "    'alpha':np.logspace(-5,5,10),\n",
    "    'fit_intercept':[True,False]\n",
    "}\n",
    "\n",
    "lin_model=Lasso()\n",
    "\n",
    "lin_train=RegressPlayers(model=lin_model,\n",
    "                         params=lin_l_params,\n",
    "                         n_jobs=7)\n",
    "\n",
    "lin_coef, lin_pred_train, lin_opt_model=lin_train.transform(X_train,\n",
    "                                                           y_train)\n",
    "\n",
    "lin_test = RegressPlayers(model=lin_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "lin_pred_test=lin_test.transform(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lasso_model']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lin_opt_model, 'lasso_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=7)]: Done 1000 out of 1000 | elapsed:  2.1min finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28673046030938076\n",
      "ElasticNet(alpha=0.0016681005372000592, copy_X=True, fit_intercept=True,\n",
      "      l1_ratio=0.2782559402207126, max_iter=1000, normalize=False,\n",
      "      positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "0.2677670635991219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lin_e_params={\n",
    "    'alpha':np.logspace(-5,5,10),\n",
    "    'l1_ratio':np.logspace(-5,5,10),\n",
    "    'fit_intercept':[True,False]\n",
    "}\n",
    "\n",
    "lin_model=ElasticNet()\n",
    "\n",
    "lin_train=RegressPlayers(model=lin_model,\n",
    "                         params=lin_e_params,\n",
    "                         n_jobs=7)\n",
    "\n",
    "lin_coef, lin_pred_train, lin_opt_model=lin_train.transform(X_train,\n",
    "                                                           y_train)\n",
    "\n",
    "lin_test = RegressPlayers(model=lin_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "lin_pred_test=lin_test.transform(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enet_model']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lin_opt_model, 'enet_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge is the best model by a margin. So I use Ridge and Lasso in bagging and boosting ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    2.7s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018017758769571124\n",
      "AdaBoostRegressor(base_estimator=Ridge(alpha=46.41588833612782, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "         learning_rate=1.0, loss='linear', n_estimators=10000,\n",
      "         random_state=None)\n",
      "coef is empty!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18851401785781363\n"
     ]
    }
   ],
   "source": [
    "lin_r_params={\n",
    "    'alpha':np.logspace(-5,5,10),\n",
    "    'fit_intercept':[True,False]\n",
    "}\n",
    "\n",
    "lin_model=Ridge()\n",
    "\n",
    "lin_train=RegressPlayers(model=lin_model,\n",
    "                         params=lin_r_params,\n",
    "                         n_jobs=7,\n",
    "                         boost=True)\n",
    "\n",
    "lin_coef, lin_pred_train, lin_opt_model=lin_train.transform(X_train,\n",
    "                                                           y_train)\n",
    "\n",
    "lin_test = RegressPlayers(model=lin_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "lin_pred_test=lin_test.transform(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boosted_ridge_model']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lin_opt_model,'boosted_ridge_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12121254592509922\n",
      "AdaBoostRegressor(base_estimator=Lasso(alpha=0.0001291549665014884, copy_X=True, fit_intercept=True,\n",
      "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
      "         learning_rate=1.0, loss='linear', n_estimators=10000,\n",
      "         random_state=None)\n",
      "coef is empty!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19076180303601356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lin_l_params={\n",
    "    'alpha':np.logspace(-5,5,10),\n",
    "    'fit_intercept':[True,False]\n",
    "}\n",
    "\n",
    "lin_model=Lasso()\n",
    "\n",
    "lin_train=RegressPlayers(model=lin_model,\n",
    "                         params=lin_l_params,\n",
    "                         n_jobs=7,\n",
    "                         boost=True)\n",
    "\n",
    "lin_coef, lin_pred_train, lin_opt_model=lin_train.transform(X_train,\n",
    "                                                           y_train)\n",
    "\n",
    "lin_test = RegressPlayers(model=lin_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "lin_pred_test=lin_test.transform(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boosted_lasso_model']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lin_opt_model,'boosted_lasso_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    4.0s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2867328008553251\n",
      "BaggingRegressor(base_estimator=Ridge(alpha=46.41588833612782, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=200, n_jobs=7, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "coef is empty!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2677701033370579\n"
     ]
    }
   ],
   "source": [
    "lin_r_params={\n",
    "    'alpha':np.logspace(-5,5,10),\n",
    "    'fit_intercept':[True,False]\n",
    "}\n",
    "\n",
    "lin_model=Ridge()\n",
    "\n",
    "lin_train=RegressPlayers(model=lin_model,\n",
    "                         params=lin_r_params,\n",
    "                         n_jobs=7,\n",
    "                         bag=True)\n",
    "\n",
    "lin_coef, lin_pred_train, lin_opt_model=lin_train.transform(X_train,\n",
    "                                                           y_train)\n",
    "\n",
    "lin_test = RegressPlayers(model=lin_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "lin_pred_test=lin_test.transform(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bagged_ridge_model']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lin_opt_model,'bagged_ridge_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=7)]: Done 100 out of 100 | elapsed:    5.4s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2867569063715802\n",
      "BaggingRegressor(base_estimator=Lasso(alpha=0.0016681005372000592, copy_X=True, fit_intercept=True,\n",
      "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=200, n_jobs=7, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "coef is empty!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26784746088636563\n"
     ]
    }
   ],
   "source": [
    "lin_l_params={\n",
    "    'alpha':np.logspace(-5,5,10),\n",
    "    'fit_intercept':[True,False]\n",
    "}\n",
    "\n",
    "lin_model=Lasso()\n",
    "\n",
    "lin_train=RegressPlayers(model=lin_model,\n",
    "                         params=lin_l_params,\n",
    "                         n_jobs=7,\n",
    "                         bag=True)\n",
    "\n",
    "lin_coef, lin_pred_train, lin_opt_model=lin_train.transform(X_train,\n",
    "                                                           y_train)\n",
    "\n",
    "lin_test = RegressPlayers(model=lin_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "lin_pred_test=lin_test.transform(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bagged_lasso_model']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lin_opt_model,'bagged_lasso_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to create the lagged error feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X_train, X_test):\n",
    "    scaler=StandardScaler()\n",
    "    X_train_ss=scaler.fit_transform(X_train)\n",
    "    X_test_ss=scaler.transform(X_test)\n",
    "    return X_train_ss, X_test_ss\n",
    "\n",
    "def nan_first_error_lag(row, df):\n",
    "    '''\n",
    "    tries to slice the dataframe at the index\n",
    "    above the row, if its the first row of a player\n",
    "    this will through an error as the index doesnt\n",
    "    exist (due to dropping these rows ealier). Hence,\n",
    "    the error term is the error of another player and \n",
    "    should not be included and is made a np.nan. If the\n",
    "    row above can be sliced then the error is returned \n",
    "    unchanged.\n",
    "    '''\n",
    "    i=row.name\n",
    "    try:\n",
    "        df.loc[i-1]\n",
    "        not_first=True\n",
    "    except:\n",
    "        not_first=False\n",
    "    \n",
    "    if not_first==False:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return row['error_lag_1']\n",
    "\n",
    "def get_error_lags(model_filename, data_filename,classify=None,threshold=None):\n",
    "    '''\n",
    "    gets the lagged errors in the X_train and X_test\n",
    "    datasets and drops the first row of each player so\n",
    "    that another players lagged error is not assigned\n",
    "    wrongly. Requires a stored model.\n",
    "    '''\n",
    "    \n",
    "    data = pd.read_csv(data_filename)\n",
    "\n",
    "    to_drop=['Unnamed: 0']\n",
    "    target='next_week_points'\n",
    "\n",
    "    footprep=FootballPreprocessor(target=target, to_drop=to_drop,\n",
    "                                 time_split=True,classify=classify,\n",
    "                                 threshold=threshold)\n",
    "\n",
    "    X_train, X_test, y_train, y_test, coef_names = footprep.transform(data)\n",
    "    \n",
    "    model=load(model_filename)\n",
    "    \n",
    "    X_train_ss, X_test_ss=standardize(X_train,X_test)\n",
    "    \n",
    "    y_train_pred=model.predict(X_train_ss)\n",
    "    y_test_pred=model.predict(X_test_ss)\n",
    "    \n",
    "    error_train=y_train - y_train_pred\n",
    "    error_test=y_test - y_test_pred\n",
    "    \n",
    "    #We now have the error columns, but that cannot be simply concated onto \n",
    "    #the dataframe and shifted down. The errors of another player will not \n",
    "    #be informative to a new player. We must drop the first row of every player \n",
    "    #after the shifted errors are added.\n",
    "    \n",
    "    X_train['errors']=error_train\n",
    "    X_test['errors']=error_test\n",
    "    \n",
    "    X_train['error_lag_1']=X_train['errors'].shift()\n",
    "    X_test['error_lag_1']=X_test['errors'].shift()\n",
    "    \n",
    "    X_train['next_week_points']=y_train\n",
    "    X_test['next_week_points']=y_test\n",
    "    #done so that the rows dropped from the features\n",
    "    #have their targets removed aswell.\n",
    "    \n",
    "    \n",
    "    X_train['error_lag_1']=X_train.apply(nan_first_error_lag,axis=1,df=X_train)\n",
    "    X_test['error_lag_1']=X_test.apply(nan_first_error_lag,axis=1,df=X_test)\n",
    "    \n",
    "    X_train.drop('errors', axis=1, inplace=True)\n",
    "    X_test.drop('errors', axis=1, inplace=True)\n",
    "    \n",
    "    X_train.dropna(inplace=True)\n",
    "    X_test.dropna(inplace=True)\n",
    "    \n",
    "    y_train=X_train.pop('next_week_points')\n",
    "    y_test=X_test.pop('next_week_points')\n",
    "    \n",
    "    \n",
    "    print('X_train: ',X_train.shape)\n",
    "    print('y_train: ',y_train.shape)\n",
    "    print('X_test: ',X_test.shape)\n",
    "    print('y_test: ',y_test.shape)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the lagged error of a players previous game in each row. Accounting for the MA(1) time dynamic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 19)\n",
      "X_train (40949, 18)\n",
      "X_test (16860, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (39638, 19)\n",
      "y_train:  (39638,)\n",
      "X_test:  (16251, 19)\n",
      "y_test:  (16251,)\n"
     ]
    }
   ],
   "source": [
    "X_train_ma,X_test_ma,y_train,y_test=get_error_lags('ridge_model','../FPL_Data/linear_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scale_fit=StandardScaler().fit(X_train_ma).scale_\n",
    "mean_fit=StandardScaler().fit(X_train_ma).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done   8 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28781494048117834\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "0.26747429976783127\n"
     ]
    }
   ],
   "source": [
    "lin_l_params={\n",
    "    'alpha':np.logspace(-5,5,10),\n",
    "    'fit_intercept':[True,False]\n",
    "}\n",
    "\n",
    "lin_model=Ridge()\n",
    "\n",
    "lin_train=RegressPlayers(model=lin_model,\n",
    "                         params=lin_params,\n",
    "                         n_jobs=7)\n",
    "\n",
    "lin_coef, lin_pred_train, lin_opt_model=lin_train.transform(X_train_ma,\n",
    "                                                           y_train)\n",
    "\n",
    "lin_test = RegressPlayers(model=lin_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "lin_pred_test=lin_test.transform(X_test_ma,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ma_ridge_model']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lin_opt_model, 'ma_ridge_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 69)\n",
      "X_train (40949, 68)\n",
      "X_test (16860, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../FPL_Data/tree_data.csv')\n",
    "\n",
    "to_drop=['Unnamed: 0']\n",
    "target='next_week_points'\n",
    "\n",
    "footprep=FootballPreprocessor(target=target, to_drop=to_drop,\n",
    "                             time_split=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test, coef_names = footprep.transform(data)\n",
    "\n",
    "scale_fit=StandardScaler().fit(X_train).scale_\n",
    "mean_fit=StandardScaler().fit(X_train).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=7)]: Done 240 out of 240 | elapsed:   18.1s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2622353770253435\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=500, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='random')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23802793648328782\n"
     ]
    }
   ],
   "source": [
    "tree_params={\n",
    "    'splitter':['best','random'],\n",
    "    'min_samples_split':[500,100,50,30],\n",
    "    'max_features':['auto', 'sqrt'],\n",
    "    'max_leaf_nodes':[None, 4, 2]\n",
    "}\n",
    "\n",
    "tree_model=DecisionTreeRegressor()\n",
    "\n",
    "tree_train=RegressPlayers(model=tree_model,\n",
    "                          params=tree_params,\n",
    "                          n_jobs=7)\n",
    "\n",
    "tree_coef, tree_pred_train, tree_opt_model=tree_train.transform(X_train,\n",
    "                                                                y_train)\n",
    "\n",
    "tree_test=RegressPlayers(model=tree_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "tree_pred_test=tree_test.transform(X_test,\n",
    "                                   y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tree_reg_model']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(tree_opt_model, 'tree_reg_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=7)]: Done 240 out of 240 | elapsed:   29.4s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6709916907734584\n",
      "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=500, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='random'),\n",
      "         learning_rate=1.0, loss='linear', n_estimators=500,\n",
      "         random_state=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7714793974793132\n"
     ]
    }
   ],
   "source": [
    "tree_params={\n",
    "    'splitter':['best','random'],\n",
    "    'min_samples_split':[500,100,50,30],\n",
    "    'max_features':['auto', 'sqrt'],\n",
    "    'max_leaf_nodes':[None, 4, 2]\n",
    "}\n",
    "\n",
    "tree_model=DecisionTreeRegressor()\n",
    "\n",
    "tree_train=RegressPlayers(model=tree_model,\n",
    "                          params=tree_params,\n",
    "                          n_jobs=7,\n",
    "                          boost=True)\n",
    "\n",
    "tree_coef, tree_pred_train, tree_opt_model=tree_train.transform(X_train,\n",
    "                                                                y_train)\n",
    "\n",
    "tree_test=RegressPlayers(model=tree_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "tree_pred_test=tree_test.transform(X_test,\n",
    "                                   y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boosted_tree_reg_model']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(tree_opt_model, 'boosted_tree_reg_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 23.5min\n",
      "[Parallel(n_jobs=4)]: Done 360 out of 360 | elapsed: 28.6min finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2951205905715425\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
      "           max_features=10, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=50, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=4, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2812362591912331\n"
     ]
    }
   ],
   "source": [
    "forest_params={\n",
    "    'max_depth':[None,20,10,5,3,2],\n",
    "    'min_samples_split':[500,100,50,30],\n",
    "    'max_features':['auto','sqrt',10]\n",
    "}\n",
    "\n",
    "forest_model=RandomForestRegressor(n_estimators=100,\n",
    "                                   n_jobs=4)\n",
    "\n",
    "forest_train=RegressPlayers(model=forest_model,\n",
    "                           params=forest_params,\n",
    "                           n_jobs=4)\n",
    "\n",
    "forest_coef, forest_pred_train, forest_opt_model=forest_train.transform(X_train,\n",
    "                                                                        y_train)\n",
    "\n",
    "forest_test=RegressPlayers(model=forest_opt_model,\n",
    "                          test=True,\n",
    "                          scale_fit=scale_fit,\n",
    "                          mean_fit=mean_fit)\n",
    "\n",
    "forest_pred_test=forest_test.transform(X_test,\n",
    "                                       y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forest_reg_model']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(forest_opt_model, 'forest_reg_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add MA(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 69)\n",
      "X_train (40949, 68)\n",
      "X_test (16860, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (39638, 69)\n",
      "y_train:  (39638,)\n",
      "X_test:  (16251, 69)\n",
      "y_test:  (16251,)\n"
     ]
    }
   ],
   "source": [
    "X_train_ma,X_test_ma,y_train,y_test=get_error_lags('forest_reg_model','../FPL_Data/tree_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scale_fit=StandardScaler().fit(X_train_ma).scale_\n",
    "mean_fit=StandardScaler().fit(X_train_ma).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=4)]: Done 360 out of 360 | elapsed: 28.5min finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2969693505615486\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=10, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=50, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=4, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:538: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2791099237752414\n"
     ]
    }
   ],
   "source": [
    "forest_params={\n",
    "    'max_depth':[None,20,10,5,3,2],\n",
    "    'min_samples_split':[500,100,50,30],\n",
    "    'max_features':['auto','sqrt',10]\n",
    "}\n",
    "\n",
    "forest_model=RandomForestRegressor(n_estimators=100,\n",
    "                                   n_jobs=4)\n",
    "\n",
    "forest_train=RegressPlayers(model=forest_model,\n",
    "                           params=forest_params,\n",
    "                           n_jobs=4)\n",
    "\n",
    "forest_coef, forest_pred_train, forest_opt_model=forest_train.transform(X_train_ma,\n",
    "                                                                        y_train)\n",
    "\n",
    "forest_test=RegressPlayers(model=forest_opt_model,\n",
    "                          test=True,\n",
    "                          scale_fit=scale_fit,\n",
    "                          mean_fit=mean_fit)\n",
    "\n",
    "forest_pred_test=forest_test.transform(X_test_ma,\n",
    "                                       y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ma_forest_reg_model']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(forest_opt_model, 'ma_forest_reg_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 19)\n",
      "X_train (40949, 18)\n",
      "X_test (16860, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('linear_data.csv')\n",
    "\n",
    "to_drop=['Unnamed: 0']\n",
    "target='next_week_points'\n",
    "\n",
    "footprep=FootballPreprocessor(target=target, to_drop=to_drop,\n",
    "                             time_split=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test, coef_names = footprep.transform(data)\n",
    "\n",
    "scale_fit=StandardScaler().fit(X_train).scale_\n",
    "mean_fit=StandardScaler().fit(X_train).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40000 candidates, totalling 200000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed: 26.7min\n"
     ]
    }
   ],
   "source": [
    "svr_params={\n",
    "    'kernel':['poly','rbf','sigmoid','linear'],\n",
    "    'gamma':np.logspace(-10,10,10),\n",
    "    'coef0':np.logspace(-5,5,10),\n",
    "    'C':np.logspace(-5,5,10),\n",
    "    'epsilon':np.logspace(-5,5,10)\n",
    "}\n",
    "\n",
    "svr_model=SVR()\n",
    "\n",
    "svr_train=RegressPlayers(model=svr_model,\n",
    "                         params=svr_params,\n",
    "                         n_jobs=3)\n",
    "\n",
    "svr_coef, svr_pred_train, svr_opt_model=svr_train.transform(X_train,\n",
    "                                                            y_train)\n",
    "\n",
    "svr_test=Regress_Players(model=svr_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "svr_pred_test=svr_test.transform(X_train,\n",
    "                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(svr_opt_model, 'svr_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 19)\n",
      "X_train (40949, 18)\n",
      "X_test (16860, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../FPL_Data/linear_data.csv')\n",
    "\n",
    "to_drop=['Unnamed: 0']\n",
    "target='next_week_points'\n",
    "\n",
    "footprep=FootballPreprocessor(target=target, to_drop=to_drop,\n",
    "                             time_split=True,classify=True,threshold=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test, coef_names = footprep.transform(data)\n",
    "\n",
    "scale_fit=StandardScaler().fit(X_train).scale_\n",
    "mean_fit=StandardScaler().fit(X_train).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36049\n",
       "1     4900\n",
       "Name: next_week_points, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=3)]: Done  80 out of  80 | elapsed:    9.3s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8811203865043339\n",
      "LogisticRegression(C=0.021544346900318846, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l1', random_state=None,\n",
      "          solver='warn', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8811203865043339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "log_params={\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-5,5,4),\n",
    "    'class_weight':[None,'balanced']\n",
    "}\n",
    "\n",
    "log_model=LogisticRegression()\n",
    "\n",
    "log_train=ClassifyPlayers(model=log_model,\n",
    "                         params=log_params,\n",
    "                         n_jobs=3)\n",
    "\n",
    "log_coef, log_pred_train, log_opt_model=log_train.transform(X_train,\n",
    "                                                            y_train)\n",
    "\n",
    "log_test=ClassifyPlayers(model=log_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "log_pred_test=log_test.transform(X_train,\n",
    "                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log_model']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(log_opt_model, 'log_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=7)]: Done  80 out of  80 | elapsed:   27.8s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27037677975617\n",
      "Pipeline(memory=None,\n",
      "     steps=[('adasyn', ADASYN(n_jobs=1, n_neighbors=20, random_state=None, ratio=None,\n",
      "    sampling_strategy='auto')), ('logisticregression', LogisticRegression(C=46.41588833612782, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l1', random_state=None,\n",
      "          solver='warn', tol=0.0001, verbose=0, warm_start=False))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27071194008161853\n"
     ]
    }
   ],
   "source": [
    "log_params={\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-5,5,4),\n",
    "    'class_weight':[None,'balanced']\n",
    "}\n",
    "\n",
    "balparams={\n",
    "    'logisticregression__penalty':['l1','l2'],\n",
    "    'logisticregression__C':np.logspace(-5,5,4),\n",
    "    'logisticregression__class_weight':[None,'balanced']\n",
    "}\n",
    "\n",
    "log_model=LogisticRegression()\n",
    "\n",
    "log_train=ClassifyPlayers(model=log_model,\n",
    "                         params=log_params,\n",
    "                         n_jobs=7,balance='adasyn',\n",
    "                         balparams=balparams)\n",
    "\n",
    "log_coef, log_pred_train, log_opt_model=log_train.transform(X_train,\n",
    "                                                            y_train)\n",
    "\n",
    "log_test=ClassifyPlayers(model=log_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "log_pred_test=log_test.transform(X_train,\n",
    "                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bal_adasyn_log_model']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(log_opt_model, 'bal_adasyn_log_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=7)]: Done  80 out of  80 | elapsed:   24.8s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('smote', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
      "   out_step='deprecated', random_state=None, ratio=None,\n",
      "   sampling_strategy='auto', svm_estimator='deprecated')), ('logisticregression', LogisticRegression(C=46.41588833612782, class_weight='balanced', dua...penalty='l1', random_state=None,\n",
      "          solver='warn', tol=0.0001, verbose=0, warm_start=False))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2765777026337671\n",
      "Pipeline(memory=None,\n",
      "     steps=[('smote', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
      "   out_step='deprecated', random_state=None, ratio=None,\n",
      "   sampling_strategy='auto', svm_estimator='deprecated')), ('logisticregression', LogisticRegression(C=46.41588833612782, class_weight='balanced', dua...penalty='l1', random_state=None,\n",
      "          solver='warn', tol=0.0001, verbose=0, warm_start=False))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27626609084669396\n"
     ]
    }
   ],
   "source": [
    "log_params={\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-5,5,4),\n",
    "    'class_weight':[None,'balanced']\n",
    "}\n",
    "\n",
    "balparams={\n",
    "    'logisticregression__penalty':['l1','l2'],\n",
    "    'logisticregression__C':np.logspace(-5,5,4),\n",
    "    'logisticregression__class_weight':[None,'balanced']\n",
    "}\n",
    "\n",
    "log_model=LogisticRegression()\n",
    "\n",
    "log_train=ClassifyPlayers(model=log_model,\n",
    "                         params=log_params,\n",
    "                         n_jobs=7,balance='smote',\n",
    "                         balparams=balparams)\n",
    "\n",
    "log_coef, log_pred_train, log_opt_model=log_train.transform(X_train,\n",
    "                                                            y_train)\n",
    "\n",
    "log_test=ClassifyPlayers(model=log_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "log_pred_test=log_test.transform(X_train,\n",
    "                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bal_smote_log_model']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(log_opt_model, 'bal_smote_log_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  80 out of  80 | elapsed:    4.9s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5255742824109926\n",
      "LogisticRegression(C=0.021544346900318846, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l1', random_state=None,\n",
      "          solver='warn', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5255742824109926\n"
     ]
    }
   ],
   "source": [
    "log_params={\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-5,5,4),\n",
    "    'class_weight':[None,'balanced']\n",
    "}\n",
    "\n",
    "balparams={\n",
    "    'logisticregression__penalty':['l1','l2'],\n",
    "    'logisticregression__C':np.logspace(-5,5,4),\n",
    "    'logisticregression__class_weight':[None,'balanced']\n",
    "}\n",
    "\n",
    "log_model=LogisticRegression()\n",
    "\n",
    "log_train=ClassifyPlayers(model=log_model,\n",
    "                         params=log_params,\n",
    "                         n_jobs=7,balance='random',\n",
    "                         balparams=balparams)\n",
    "\n",
    "log_coef, log_pred_train, log_opt_model=log_train.transform(X_train,\n",
    "                                                            y_train)\n",
    "\n",
    "log_test=ClassifyPlayers(model=log_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "log_pred_test=log_test.transform(X_train,\n",
    "                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bal_random_log_model']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(log_opt_model, 'bal_random_log_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 19)\n",
      "X_train (40949, 18)\n",
      "X_test (16860, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (39638, 19)\n",
      "y_train:  (39638,)\n",
      "X_test:  (16251, 19)\n",
      "y_test:  (16251,)\n"
     ]
    }
   ],
   "source": [
    "X_train_ma,X_test_ma,y_train,y_test=get_error_lags('bal_random_log_model',\n",
    "                                                    '../FPL_Data/linear_data.csv',\n",
    "                                                  classify=True, threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scale_fit=StandardScaler().fit(X_train_ma).scale_\n",
    "mean_fit=StandardScaler().fit(X_train_ma).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=7)]: Done  80 out of  80 | elapsed:    7.3s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50991462615854\n",
      "LogisticRegression(C=0.021544346900318846, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l1', random_state=None,\n",
      "          solver='warn', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50991462615854\n"
     ]
    }
   ],
   "source": [
    "log_params={\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-5,5,4),\n",
    "    'class_weight':[None,'balanced']\n",
    "}\n",
    "\n",
    "balparams={\n",
    "    'logisticregression__penalty':['l1','l2'],\n",
    "    'logisticregression__C':np.logspace(-5,5,4),\n",
    "    'logisticregression__class_weight':[None,'balanced']\n",
    "}\n",
    "\n",
    "log_model=LogisticRegression()\n",
    "\n",
    "log_train=ClassifyPlayers(model=log_model,\n",
    "                         params=log_params,\n",
    "                         n_jobs=7,balance='random',\n",
    "                         balparams=balparams)\n",
    "\n",
    "log_coef, log_pred_train, log_opt_model=log_train.transform(X_train_ma,\n",
    "                                                            y_train)\n",
    "\n",
    "log_test=ClassifyPlayers(model=log_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "log_pred_test=log_test.transform(X_train_ma,\n",
    "                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ma_bal_random_log_model']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(log_opt_model, 'ma_bal_random_log_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 69)\n",
      "X_train (40949, 68)\n",
      "X_test (16860, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../FPL_Data/tree_data.csv')\n",
    "\n",
    "to_drop=['Unnamed: 0']\n",
    "target='next_week_points'\n",
    "\n",
    "footprep=FootballPreprocessor(target=target, to_drop=to_drop,\n",
    "                             time_split=True,classify=True,threshold=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test, coef_names = footprep.transform(data)\n",
    "\n",
    "scale_fit=StandardScaler().fit(X_train).scale_\n",
    "mean_fit=StandardScaler().fit(X_train).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=7)]: Done 240 out of 240 | elapsed:   14.6s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24375127006705954\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=500,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random')\n",
      "0.3817485196795542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tree_params={\n",
    "    'splitter':['best','random'],\n",
    "    'min_samples_split':[500,100,50,30],\n",
    "    'max_features':['auto', 'sqrt'],\n",
    "    'max_leaf_nodes':[None, 4, 2]\n",
    "}\n",
    "\n",
    "tree_model=DecisionTreeClassifier()\n",
    "\n",
    "tree_train=ClassifyPlayers(model=tree_model,\n",
    "                          params=tree_params,\n",
    "                          n_jobs=7)\n",
    "\n",
    "tree_coef, tree_pred_train, tree_opt_model=tree_train.transform(X_train,\n",
    "                                                                y_train)\n",
    "\n",
    "tree_test=ClassifyPlayers(model=tree_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "tree_pred_test=tree_test.transform(X_test,\n",
    "                                   y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tree_class_model']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(tree_opt_model, 'tree_class_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 69)\n",
      "X_train (40949, 68)\n",
      "X_test (16860, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (39638, 69)\n",
      "y_train:  (39638,)\n",
      "X_test:  (16251, 69)\n",
      "y_test:  (16251,)\n"
     ]
    }
   ],
   "source": [
    "X_train_ma,X_test_ma,y_train,y_test=get_error_lags('tree_class_model',\n",
    "                                                     '../FPL_Data/tree_data.csv',classify=True,\n",
    "                                                   threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scale_fit=StandardScaler().fit(X_train_ma).scale_\n",
    "mean_fit=StandardScaler().fit(X_train_ma).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=3)]: Done 240 out of 240 | elapsed:   21.2s finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3817571259765698\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=500,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14671814671814673\n"
     ]
    }
   ],
   "source": [
    "tree_params={\n",
    "    'splitter':['best','random'],\n",
    "    'min_samples_split':[500,100,50,30],\n",
    "    'max_features':['auto', 'sqrt'],\n",
    "    'max_leaf_nodes':[None, 4, 2]\n",
    "}\n",
    "\n",
    "tree_model=DecisionTreeClassifier()\n",
    "\n",
    "tree_train=ClassifyPlayers(model=tree_model,\n",
    "                          params=tree_params,\n",
    "                          n_jobs=3)\n",
    "\n",
    "tree_coef, tree_pred_train, tree_opt_model=tree_train.transform(X_train_ma,\n",
    "                                                                y_train)\n",
    "\n",
    "tree_test=ClassifyPlayers(model=tree_opt_model,\n",
    "                         test=True,\n",
    "                         scale_fit=scale_fit,\n",
    "                         mean_fit=mean_fit)\n",
    "\n",
    "tree_pred_test=tree_test.transform(X_test_ma,\n",
    "                                   y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ma_tree_class_model']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(tree_opt_model, 'ma_tree_class_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 69)\n",
      "X_train (40949, 68)\n",
      "X_test (16860, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../FPL_Data/tree_data.csv')\n",
    "\n",
    "to_drop=['Unnamed: 0']\n",
    "target='next_week_points'\n",
    "\n",
    "footprep=FootballPreprocessor(target=target, to_drop=to_drop,\n",
    "                             time_split=True,classify=True,threshold=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test, coef_names = footprep.transform(data)\n",
    "\n",
    "scale_fit=StandardScaler().fit(X_train).scale_\n",
    "mean_fit=StandardScaler().fit(X_train).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed: 23.5min\n",
      "[Parallel(n_jobs=5)]: Done 360 out of 360 | elapsed: 31.4min finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=10, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=500,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=3,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "forest_params={\n",
    "    'max_depth':[None,20,10,5,3,2],\n",
    "    'min_samples_split':[500,100,50,30],\n",
    "    'max_features':['auto','sqrt',10] \n",
    "}\n",
    "\n",
    "forest_model=RandomForestClassifier(n_estimators=300,\n",
    "                                   n_jobs=3)\n",
    "\n",
    "forest_train=ClassifyPlayers(model=forest_model,\n",
    "                           params=forest_params,\n",
    "                           n_jobs=5)\n",
    "\n",
    "forest_coef, forest_pred_train, forest_opt_model=forest_train.transform(X_train,\n",
    "                                                                        y_train)\n",
    "\n",
    "forest_test=ClassifyPlayers(model=forest_opt_model,\n",
    "                          test=True,\n",
    "                          scale_fit=scale_fit,\n",
    "                          mean_fit=mean_fit)\n",
    "\n",
    "forest_pred_test=forest_test.transform(X_test,\n",
    "                                       y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forest_class_model']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(forest_opt_model, 'forest_class_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 69)\n",
      "X_train (40949, 68)\n",
      "X_test (16860, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (39638, 69)\n",
      "y_train:  (39638,)\n",
      "X_test:  (16251, 69)\n",
      "y_test:  (16251,)\n"
     ]
    }
   ],
   "source": [
    "X_train_ma,X_test_ma,y_train,y_test=get_error_lags('forest_class_model',\n",
    "                                                     '../FPL_Data/tree_data.csv',\n",
    "                                                  classify=True,\n",
    "                                                  threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scale_fit=StandardScaler().fit(X_train_ma).scale_\n",
    "mean_fit=StandardScaler().fit(X_train_ma).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=5)]: Done 360 out of 360 | elapsed: 30.9min finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5458664503919978\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=30,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=3,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6827651515151515\n"
     ]
    }
   ],
   "source": [
    "forest_params={\n",
    "    'max_depth':[None,20,10,5,3,2],\n",
    "    'min_samples_split':[500,100,50,30],\n",
    "    'max_features':['auto','sqrt',10] \n",
    "}\n",
    "\n",
    "forest_model=RandomForestClassifier(n_estimators=300,\n",
    "                                   n_jobs=3)\n",
    "\n",
    "forest_train=ClassifyPlayers(model=forest_model,\n",
    "                           params=forest_params,\n",
    "                           n_jobs=5)\n",
    "\n",
    "forest_coef, forest_pred_train, forest_opt_model=forest_train.transform(X_train_ma,\n",
    "                                                                        y_train)\n",
    "\n",
    "forest_test=ClassifyPlayers(model=forest_opt_model,\n",
    "                          test=True,\n",
    "                          scale_fit=scale_fit,\n",
    "                          mean_fit=mean_fit)\n",
    "\n",
    "forest_pred_test=forest_test.transform(X_test_ma,\n",
    "                                       y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ma_forest_class_model']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(forest_opt_model, 'ma_forest_class_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 69)\n",
      "X_train (40949, 68)\n",
      "X_test (16860, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../FPL_Data/tree_data.csv')\n",
    "\n",
    "to_drop=['Unnamed: 0']\n",
    "target='next_week_points'\n",
    "\n",
    "footprep=FootballPreprocessor(target=target, to_drop=to_drop,\n",
    "                             time_split=True,classify=True,threshold=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test, coef_names = footprep.transform(data)\n",
    "\n",
    "scale_fit=StandardScaler().fit(X_train).scale_\n",
    "mean_fit=StandardScaler().fit(X_train).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=5)]: Done 360 out of 360 | elapsed: 33.2min finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=10, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=500,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=3,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "forest_params={\n",
    "    'max_depth':[None,20,10,5,3,2],\n",
    "    'min_samples_split':[500,100,50,30],\n",
    "    'max_features':['auto','sqrt',10] \n",
    "}\n",
    "\n",
    "balparams={\n",
    "    'randomforestclassifier__max_depth':[None,20,10,5,3,2],\n",
    "    'randomforestclassifier__min_samples_split':[500,100,50,30],\n",
    "    'randomforestclassifier__max_features':['auto','sqrt',10] \n",
    "}\n",
    "\n",
    "forest_model=RandomForestClassifier(n_estimators=300,\n",
    "                                   n_jobs=3)\n",
    "\n",
    "forest_train=ClassifyPlayers(model=forest_model,\n",
    "                           params=forest_params,\n",
    "                           n_jobs=5, balance='random',\n",
    "                            balparams=balparams)\n",
    "\n",
    "forest_coef, forest_pred_train, forest_opt_model=forest_train.transform(X_train,\n",
    "                                                                        y_train)\n",
    "\n",
    "forest_test=ClassifyPlayers(model=forest_opt_model,\n",
    "                          test=True,\n",
    "                          scale_fit=scale_fit,\n",
    "                          mean_fit=mean_fit)\n",
    "\n",
    "forest_pred_test=forest_test.transform(X_test,\n",
    "                                       y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bal_random_forest_class_model']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(forest_opt_model, 'bal_random_forest_class_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed: 66.6min\n",
      "[Parallel(n_jobs=5)]: Done 360 out of 360 | elapsed: 90.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('smote', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
      "   out_step='deprecated', random_state=None, ratio=None,\n",
      "   sampling_strategy='auto', svm_estimator='deprecated')), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criter...n_jobs=3,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3751078415771145\n",
      "Pipeline(memory=None,\n",
      "     steps=[('smote', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
      "   out_step='deprecated', random_state=None, ratio=None,\n",
      "   sampling_strategy='auto', svm_estimator='deprecated')), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criter...n_jobs=3,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4004178687824911\n"
     ]
    }
   ],
   "source": [
    "forest_params={\n",
    "    'max_depth':[None,20,10,5,3,2],\n",
    "    'min_samples_split':[500,100,50,30],\n",
    "    'max_features':['auto','sqrt',10] \n",
    "}\n",
    "\n",
    "balparams={\n",
    "    'randomforestclassifier__max_depth':[None,20,10,5,3,2],\n",
    "    'randomforestclassifier__min_samples_split':[500,100,50,30],\n",
    "    'randomforestclassifier__max_features':['auto','sqrt',10] \n",
    "}\n",
    "\n",
    "forest_model=RandomForestClassifier(n_estimators=300,\n",
    "                                   n_jobs=3)\n",
    "\n",
    "forest_train=ClassifyPlayers(model=forest_model,\n",
    "                           params=forest_params,\n",
    "                           n_jobs=5, balance='smote',\n",
    "                            balparams=balparams)\n",
    "\n",
    "forest_coef, forest_pred_train, forest_opt_model=forest_train.transform(X_train,\n",
    "                                                                        y_train)\n",
    "\n",
    "forest_test=ClassifyPlayers(model=forest_opt_model,\n",
    "                          test=True,\n",
    "                          scale_fit=scale_fit,\n",
    "                          mean_fit=mean_fit)\n",
    "\n",
    "forest_pred_test=forest_test.transform(X_test,\n",
    "                                       y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bal_smote_forest_class_model']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(forest_opt_model, 'bal_smote_forest_class_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed: 65.4min\n",
      "[Parallel(n_jobs=5)]: Done 360 out of 360 | elapsed: 90.8min finished\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3602351235589763\n",
      "Pipeline(memory=None,\n",
      "     steps=[('adasyn', ADASYN(n_jobs=1, n_neighbors=20, random_state=None, ratio=None,\n",
      "    sampling_strategy='auto')), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=10, max_leaf_nodes=None,\n",
      "            min_imp...n_jobs=3,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3943705308955294\n"
     ]
    }
   ],
   "source": [
    "forest_params={\n",
    "    'max_depth':[None,20,10,5,3,2],\n",
    "    'min_samples_split':[500,100,50,30],\n",
    "    'max_features':['auto','sqrt',10] \n",
    "}\n",
    "\n",
    "balparams={\n",
    "    'randomforestclassifier__max_depth':[None,20,10,5,3,2],\n",
    "    'randomforestclassifier__min_samples_split':[500,100,50,30],\n",
    "    'randomforestclassifier__max_features':['auto','sqrt',10] \n",
    "}\n",
    "\n",
    "forest_model=RandomForestClassifier(n_estimators=300,\n",
    "                                   n_jobs=3)\n",
    "\n",
    "forest_train=ClassifyPlayers(model=forest_model,\n",
    "                           params=forest_params,\n",
    "                           n_jobs=5, balance='adasyn',\n",
    "                            balparams=balparams)\n",
    "\n",
    "forest_coef, forest_pred_train, forest_opt_model=forest_train.transform(X_train,\n",
    "                                                                        y_train)\n",
    "\n",
    "forest_test=ClassifyPlayers(model=forest_opt_model,\n",
    "                          test=True,\n",
    "                          scale_fit=scale_fit,\n",
    "                          mean_fit=mean_fit)\n",
    "\n",
    "forest_pred_test=forest_test.transform(X_test,\n",
    "                                       y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bal_adasyn_forest_class_model']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(forest_opt_model, 'bal_adasyn_forest_class_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (57809, 69)\n",
      "X_train (40949, 68)\n",
      "X_test (16860, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (39638, 69)\n",
      "y_train:  (39638,)\n",
      "X_test:  (16251, 69)\n",
      "y_test:  (16251,)\n"
     ]
    }
   ],
   "source": [
    "X_train_ma,X_test_ma,y_train,y_test=get_error_lags('bal_smote_forest_class_model',\n",
    "                                                     '../FPL_Data/tree_data.csv',\n",
    "                                                  classify=True,\n",
    "                                                  threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scale_fit=StandardScaler().fit(X_train_ma).scale_\n",
    "mean_fit=StandardScaler().fit(X_train_ma).mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39638, 69)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39638,)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 65.2min\n",
      "[Parallel(n_jobs=4)]: Done 360 out of 360 | elapsed: 87.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('smote', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
      "   out_step='deprecated', random_state=None, ratio=None,\n",
      "   sampling_strategy='auto', svm_estimator='deprecated')), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criter...n_jobs=3,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36938272912769915\n",
      "Pipeline(memory=None,\n",
      "     steps=[('smote', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
      "   out_step='deprecated', random_state=None, ratio=None,\n",
      "   sampling_strategy='auto', svm_estimator='deprecated')), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criter...n_jobs=3,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:283: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\linne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4072592295316599\n"
     ]
    }
   ],
   "source": [
    "forest_params={\n",
    "    'max_depth':[None,20,10,5,3,2],\n",
    "    'min_samples_split':[500,100,50,30],\n",
    "    'max_features':['auto','sqrt',10] \n",
    "}\n",
    "\n",
    "balparams={\n",
    "    'randomforestclassifier__max_depth':[None,20,10,5,3,2],\n",
    "    'randomforestclassifier__min_samples_split':[500,100,50,30],\n",
    "    'randomforestclassifier__max_features':['auto','sqrt',10] \n",
    "}\n",
    "\n",
    "forest_model=RandomForestClassifier(n_estimators=300,\n",
    "                                   n_jobs=3)\n",
    "\n",
    "forest_train=ClassifyPlayers(model=forest_model,\n",
    "                           params=forest_params,\n",
    "                           balance='smote',\n",
    "                           balparams=balparams,\n",
    "                           n_jobs=4)\n",
    "\n",
    "forest_coef, forest_pred_train, forest_opt_model=forest_train.transform(X_train_ma,\n",
    "                                                                        y_train)\n",
    "\n",
    "forest_test=ClassifyPlayers(model=forest_opt_model,\n",
    "                          test=True,\n",
    "                          scale_fit=scale_fit,\n",
    "                          mean_fit=mean_fit)\n",
    "\n",
    "forest_pred_test=forest_test.transform(X_test_ma,\n",
    "                                       y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ma_bal_smote_forest_class_model']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(forest_opt_model, 'ma_bal_smote_forest_class_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('smote', SMOTE(k_neighbors=5, kind='deprecated', m_neighbors='deprecated', n_jobs=1,\n",
       "   out_step='deprecated', random_state=None, ratio=None,\n",
       "   sampling_strategy='auto', svm_estimator='deprecated')), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criter...n_jobs=3,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_opt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
